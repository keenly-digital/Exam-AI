{
    "topics": {
        "topic1": {
            "topic_name": "Describe Artificial Intelligence workloads and considerations",
            "case_study": "",
            "questions": [
                {
                    "question_number": "1",
                    "question": "A company employs a team of customer service agents to provide telephone and email support to\ncustomers.\nThe company develops a webchat bot to provide automated answers to common customer queries.\nWhich business benefit should the company expect as a result of creating the webchat bot solution?",
                    "options": [
                        "A. increased sales",
                        "B. a reduced workload for the customer service agents",
                        "C. improved product reliability"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "2",
                    "question": "For a machine learning progress, how should you split data for training and evaluation?",
                    "options": [
                        "A. Use features for training and labels for evaluation.",
                        "B. Randomly split the data into rows for training and rows for evaluation.",
                        "C. Use labels for training and features for evaluation.",
                        "D. Randomly split the data into columns for training and columns for evaluation."
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "https://docs.microsoft.com/en-us/azure/machine-learning/algorithm-module-reference/split-data"
                },
                {
                    "question_number": "3",
                    "question": "HOTSPOT\nYou are developing a model to predict events by using classification.\nYou have a confusion matrix for the model scored on test data as shown in the following exhibit.\n<img src='images/page_3_img_1.jpg'>\nUse the drop-down menus to select the answer choice that completes each statement based on the\ninformation presented in the graphic.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_4_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_5_img_1.jpg'>\nBox 1: 11\n<img src='images/page_5_img_2.jpg'>\nTP = True Positive.\nThe class labels in the training set can take on only two possible values, which we usually refer to as\npositive or negative. The positive and negative instances that a classifier predicts correctly are called\ntrue positives (TP) and true negatives (TN), respectively. Similarly, the incorrectly classified instances\nare called false positives (FP) and false negatives (FN).\nBox 2: 1,033\nFN = False Negative\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio/evaluate-model-performance\nFinding TP is easy. It basically means the value where Predicted and True value is 1 and that is 11 in\nthis case.\nFalse Negative means where true value was 1 but predicted value was 0 and that is 1033 in this case\nThe confusion matrix shows cases where both the predicted and actual values were 1 (known as true\npositives) at the top left, and cases where both the predicted and the actual values were 0 (true\nnegatives) at the bottom right. The other cells show cases where the predicted and actual values\ndiffer (false positives and false negatives).\nhttps://docs.microsoft.com/en-us/learn/modules/create-classification-model-azure-machine-\nlearning-designer/evaluate-model"
                },
                {
                    "question_number": "4",
                    "question": "You build a machine learning model by using the automated machine learning user interface (UI).\nYou need to ensure that the model meets the Microsoft transparency principle for responsible AI.\nWhat should you do?",
                    "options": [
                        "A. Set Validation type to Auto.",
                        "B. Enable Explain best model.",
                        "C. Set Primary metric to accuracy.",
                        "D. Set Max concurrent iterations to 0."
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "Model Explain Ability.\nMost businesses run on trust and being able to open the ML \u201cblack box\u201d helps build transparency\nand trust. In heavily regulated industries like healthcare and banking, it is critical to comply with\nregulations and best practices. One key aspect of this is understanding the relationship between\ninput variables (features) and model output. Knowing both the magnitude and direction of the\nimpact each feature (feature importance) has on the predicted value helps better understand and\nexplain the model. With model explain ability, we enable you to understand feature importance as\npart of automated ML runs.\nReference:\nhttps://azure.microsoft.com/en-us/blog/new-automated-machine-learning-capabilities-in-azure-\nmachine-learning-service/"
                },
                {
                    "question_number": "5",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_7_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_7_img_2.jpg'>\nBox 1: No\nBox 2: Yes\nBox 3: Yes\nAnomaly detection encompasses many important tasks in machine learning:\nIdentifying transactions that are potentially fraudulent.\nLearning patterns that indicate that a network intrusion has occurred.\nFinding abnormal clusters of patients.\nChecking values entered into a system.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/anomaly-\ndetection"
                },
                {
                    "question_number": "6",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_8_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "Reliability & Safety\nhttps://en.wikipedia.org/wiki/Tay_(bot)\n\u201cTo build trust, it's critical that AI systems operate reliably, safely, and consistently under normal\ncircumstances and in unexpected conditions. These systems should be able to operate as they were\noriginally designed, respond safely to unanticipated conditions, and resist harmful manipulation. It's\nalso important to be able to verify that these systems are behaving as intended under actual\noperating conditions. How they behave and the variety of conditions they can handle reliably and\nsafely largely reflects the range of situations and circumstances that developers anticipate during\ndesign and testing. We believe that rigorous testing is essential during system development and\ndeployment to ensure AI systems can respond safely in unanticipated situations and edge cases,\ndon't have unexpected performance failures, and don't evolve in ways that are inconsistent with\noriginal expectations\u201d"
                },
                {
                    "question_number": "7",
                    "question": "DRAG DROP\nMatch the types of AI workloads to the appropriate scenarios.\nTo answer, drag the appropriate workload type from the column on the left to its scenario on the\nright. Each workload type may be used once, more than once, or not at all.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_9_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_9_img_2.jpg'>\nBox 3: Natural language processing\nNatural language processing (NLP) is used for tasks such as sentiment analysis, topic detection,\nlanguage detection, key phrase extraction, and document categorization.\nReference:\nhttps://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-\nlanguage-processing"
                },
                {
                    "question_number": "8",
                    "question": "You are designing an AI system that empowers everyone, including people who have hearing, visual,\nand other impairments.\nThis is an example of which Microsoft guiding principle for responsible AI?",
                    "options": [
                        "A. fairness",
                        "B. inclusiveness",
                        "C. reliability and safety",
                        "D. accountability"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "Inclusiveness: At Microsoft, we firmly believe everyone should benefit from intelligent technology,\nmeaning it must incorporate and address a broad range of human needs and experiences. For the 1\nbillion people with disabilities around the world, AI technologies can be a game-changer.\nReference:\nhttps://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles"
                },
                {
                    "question_number": "9",
                    "question": "DRAG DROP\nMatch the Microsoft guiding principles for responsible AI to the appropriate descriptions.\nTo answer, drag the appropriate principle from the column on the left to its description on the right.\nEach principle may be used once, more than once, or not at all.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_10_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "Box 1: Reliability and safety\nTo build trust, it's critical that AI systems operate reliably, safely, and consistently under normal\ncircumstances and in unexpected conditions. These systems should be able to operate as they were\noriginally designed, respond safely to unanticipated conditions, and resist harmful manipulation.\nBox 2: accountability\nBox 3: Privacy and security\nAs AI becomes more prevalent, protecting privacy and securing important personal and business\ninformation is becoming more critical and complex. With AI, privacy and data security issues require\nespecially close attention because access to data is essential for AI systems to make accurate and\ninformed predictions and decisions about people. AI systems must comply with privacy laws that\nrequire transparency about the collection, use, and storage of data and mandate that consumers\nhave appropriate controls to choose how their data is used\nhttps://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles"
                },
                {
                    "question_number": "10",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_11_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_11_img_2.jpg'>\nReliability and safety: To build trust, it's critical that AI systems operate reliably, safely, and\nconsistently under normal circumstances and in unexpected conditions. These systems should be\nable to operate as they were originally designed, respond safely to unanticipated conditions, and\nresist harmful manipulation.\nReference:\nhttps://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles\nAI systems should perform reliably and safely. For example, consider an AI-based software system for\nan autonomous vehicle; or a machine learning model that diagnoses patient symptoms and\nrecommends prescriptions. Unreliability in these kinds of system can result in substantial risk to\nhuman life.\nhttps://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/7-understand-\nresponsible-ai"
                },
                {
                    "question_number": "11",
                    "question": "You are building an AI system.\nWhich task should you include to ensure that the service meets the Microsoft transparency principle\nfor responsible AI?",
                    "options": [
                        "A. Ensure that all visuals have an associated text that can be read by a screen reader.",
                        "B. Enable autoscaling to ensure that a service scales based on demand.",
                        "C. Provide documentation to help developers debug code.",
                        "D. Ensure that a training dataset is representative of the population."
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": "Reference:\nhttps://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles"
                },
                {
                    "question_number": "12",
                    "question": "DRAG DROP\nMatch the types of AI workloads to the appropriate scenarios.\nTo answer, drag the appropriate workload type from the column on the left to its scenario on the\nright. Each workload type may be used once, more than once, or not at all.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_13_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_13_img_2.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/learn/paths/get-started-with-artificial-intelligence-on-azure/"
                },
                {
                    "question_number": "13",
                    "question": "Your company is exploring the use of voice recognition technologies in its smart home devices. The\ncompany wants to identify any barriers that might unintentionally leave out specific user groups.\nThis an example of which Microsoft guiding principle for responsible AI?",
                    "options": [
                        "A. accountability",
                        "B. fairness",
                        "C. inclusiveness",
                        "D. privacy and security"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": "Reference:\nhttps://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles\nAI systems should empower everyone and engage people. AI should bring benefits to all parts of\nsociety, regardless of physical ability, gender,\nsexual orientation, ethnicity, or other factors.\nhttps://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/7-understand-\nresponsible-ai"
                },
                {
                    "question_number": "14",
                    "question": "What are three Microsoft guiding principles for responsible AI? Each correct answer presents a\ncomplete solution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. knowledgeability",
                        "B. decisiveness",
                        "C. inclusiveness",
                        "D. fairness",
                        "E. opinionatedness",
                        "F. reliability and safety"
                    ],
                    "answer": [
                        "C",
                        "D",
                        "F"
                    ],
                    "explanation": "Reference:\nhttps://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles"
                },
                {
                    "question_number": "15",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_15_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_15_img_2.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-\ndetection"
                },
                {
                    "question_number": "16",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_16_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_16_img_2.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/create-\nfeatures"
                },
                {
                    "question_number": "17",
                    "question": "You run a charity event that involves posting photos of people wearing sunglasses on Twitter.\nYou need to ensure that you only retweet photos that meet the following requirements:\nInclude one or more faces.\nContain at least one person wearing sunglasses.\nWhat should you use to analyze the images?",
                    "options": [
                        "A. the Verify operation in the Face service",
                        "B. the Detect operation in the Face service",
                        "C. the Describe Image operation in the Computer Vision service",
                        "D. the Analyze Image operation in the Computer Vision service"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "Reference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/face/overview"
                },
                {
                    "question_number": "18",
                    "question": "When you design an AI system to assess whether loans should be approved, the factors used to make\nthe decision should be explainable.\nThis is an example of which Microsoft guiding principle for responsible AI?",
                    "options": [
                        "A. transparency",
                        "B. inclusiveness",
                        "C. fairness",
                        "D. privacy and security"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": "Achieving transparency helps the team to understand the data and algorithms used to train the\nmodel, what transformation logic was applied to the data, the final model generated, and its\nassociated assets. This information offers insights about how the model was created, which allows it\nto be reproduced in a transparent way.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-\npractices/trusted-ai\nhttps://docs.microsoft.com/en-us/azure/cloud-adoption-framework/strategy/responsible-ai"
                },
                {
                    "question_number": "19",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_18_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_18_img_2.jpg'>\nBox 1: Yes\nAchieving transparency helps the team to understand the data and algorithms used to train the\nmodel, what transformation logic was applied to the data, the final model generated, and its\nassociated assets. This information offers insights about how the model was created, which allows it\nto be reproduced in a transparent way.\nBox 2: No\nA data holder is obligated to protect the data in an AI system, and privacy and security are an integral\npart of this system. Personal needs to be secured, and it should be accessed in a way that doesn't\ncompromise an individual's privacy.\nBox 3: No\nInclusiveness mandates that AI should consider all human races and experiences, and inclusive\ndesign practices can help developers to understand and address potential barriers that could\nunintentionally exclude people. Where possible, speech-to-text, text-to-speech, and visual\nrecognition technology should be used to empower people with hearing, visual, and other\nimpairments.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-\npractices/trusted-ai"
                },
                {
                    "question_number": "20",
                    "question": "DRAG DROP\nMatch the principles of responsible AI to appropriate requirements.\nTo answer, drag the appropriate principles from the column on the left to its requirement on the\nright. Each principle may be used once, more than once, or not at all. You may need to drag the split\nbar between panes or scroll to view content.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_19_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_19_img_2.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-\npractices/trusted-ai\nhttps://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles"
                },
                {
                    "question_number": "21",
                    "question": "DRAG DROP\nYou plan to deploy an Azure Machine Learning model as a service that will be used by client\napplications.\nWhich three processes should you perform in sequence before you deploy the model? To answer,\nmove the appropriate processes from the list of processes to the answer area and arrange them in\nthe correct order.\n<img src='images/page_20_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_20_img_2.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-ml-pipelines"
                },
                {
                    "question_number": "22",
                    "question": "You are building an AI-based app.\nYou need to ensure that the app uses the principles for responsible AI.\nWhich two principles should you follow? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. Implement an Agile software development methodology",
                        "B. Implement a process of Al model validation as part of the software review process",
                        "C. Establish a risk governance committee that includes members of the legal team, members of the\nrisk management team, and a privacy officer",
                        "D. Prevent the disclosure of the use of Al-based algorithms for automated decision making"
                    ],
                    "answer": [
                        "B",
                        "C"
                    ],
                    "explanation": "Reference:\nhttps://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-\npractices/trusted-ai\nhttps://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/3-implications-\nresponsible-ai-practical"
                },
                {
                    "question_number": "23",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_21_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_22_img_1.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-\npractices/trusted-ai"
                }
            ]
        },
        "topic2": {
            "topic_name": "Describe fundamental principles of machine learning on Azure",
            "case_study": "",
            "questions": [
                {
                    "question_number": "24",
                    "question": "Which metric can you use to evaluate a classification model?",
                    "options": [
                        "A. true positive rate",
                        "B. mean absolute error (MAE)",
                        "C. coefficient of determination (R2)",
                        "D. root mean squared error (RMSE)"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": "What does a good model look like?\nAn ROC curve that approaches the top left corner with 100% true positive rate and 0% false positive\nrate will be the best model. A random model would display as a flat line from the bottom left to the\ntop right corner. Worse than random would dip below the y=x line.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-\nml#classification"
                },
                {
                    "question_number": "25",
                    "question": "Which two components can you drag onto a canvas in Azure Machine Learning designer? Each\ncorrect answer presents a complete solution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. dataset",
                        "B. co mpute",
                        "C. pipeline",
                        "D. module"
                    ],
                    "answer": [
                        "A",
                        "D"
                    ],
                    "explanation": "You can drag-and-drop datasets and modules onto the canvas.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-designer"
                },
                {
                    "question_number": "26",
                    "question": "You need to create a training dataset and validation dataset from an existing dataset.\nWhich module in the Azure Machine Learning designer should you use?",
                    "options": [
                        "A. Select Columns in Dataset",
                        "B. Add Rows",
                        "C. Split Data",
                        "D. Join Data"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": "A common way of evaluating a model is to divide the data into a training and test set by using Split\nData, and then validate the model on the training data.\nUse the Split Data module to divide a dataset into two distinct sets.\nThe studio currently supports training/validation data splits\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-cross-validation-data-\nsplits2"
                },
                {
                    "question_number": "27",
                    "question": "DRAG DROP\nMatch the types of machine learning to the appropriate scenarios.\nTo answer, drag the appropriate machine learning type from the column on the left to its scenario on\nthe right. Each machine learning type may be used once, more than once, or not at all.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_24_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "1- Regression\n2- Clustering\n3- Classification"
                },
                {
                    "question_number": "28",
                    "question": "DRAG DROP\nMatch the machine learning tasks to the appropriate scenarios.\nTo answer, drag the appropriate task from the column on the left to its scenario on the right. Each\ntask may be used once, more than once, or not at all.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_24_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_25_img_1.jpg'>\nBox 1: Model evaluation\nThe Model evaluation module outputs a confusion matrix showing the number of true positives,\nfalse negatives, false positives, and true negatives, as well as ROC, Precision/Recall, and Lift curves.\nBox 2: Feature engineering\nFeature engineering is the process of using domain knowledge of the data to create features that\nhelp ML algorithms learn better. In Azure Machine Learning, scaling and normalization techniques\nare applied to facilitate feature engineering. Collectively, these techniques and feature engineering\nare referred to as featurization.\nNote: Often, features are created from raw data through a process of feature engineering. For\nexample, a time stamp in itself might not be useful for modeling until the information is transformed\ninto units of days, months, or categories that are relevant to the problem, such as holiday versus\nworking day.\nBox 3: Feature selection\nIn machine learning and statistics, feature selection is the process of selecting a subset of relevant,\nuseful features to use in building an analytical model. Feature selection helps narrow the field of data\nto the most valuable inputs. Narrowing the field of data helps reduce noise and improve training\nperformance.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio/evaluate-model-performance\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml"
                },
                {
                    "question_number": "29",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_26_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "Features"
                },
                {
                    "question_number": "30",
                    "question": "You have the Predicted vs. True chart shown in the following exhibit.\n<img src='images/page_26_img_2.jpg'>\nWhich type of model is the chart used to evaluate?",
                    "options": [
                        "A. classification",
                        "B. regression",
                        "C. clustering"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "What is a Predicted vs. True chart?\nPredicted vs. True shows the relationship between a predicted value and its correlating true value for\na regression problem. This graph can be used to measure performance of a model as the closer to\nthe y=x line the predicted values are, the better the accuracy of a predictive model.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-m"
                },
                {
                    "question_number": "31",
                    "question": "Which type of machine learning should you use to predict the number of gift cards that will be sold\nnext month?",
                    "options": [
                        "A. classification",
                        "B. regression",
                        "C. clustering"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "32",
                    "question": "You have a dataset that contains information about taxi journeys that occurred during a given period.\nYou need to train a model to predict the fare of a taxi journey.\nWhat should you use as a feature?",
                    "options": [
                        "A. the number of taxi journeys in the dataset",
                        "B. the trip distance of individual taxi journeys",
                        "C. the fare of individual taxi journeys",
                        "D. the trip ID of individual taxi journeys"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "The label is the column you want to predict. The identified Features are the inputs you give the\nmodel to predict the Label.\nExample:\nThe provided data set contains the following columns:\nvendor_id: The ID of the taxi vendor is a feature.\nrate_code: The rate type of the taxi trip is a feature.\npassenger_count: The number of passengers on the trip is a feature.\ntrip_time_in_secs: The amount of time the trip took. You want to predict the fare of the trip before\nthe trip is completed. At that moment, you don't know how long the trip would take. Thus, the trip\ntime is not a feature and you'll exclude this column from the model.\ntrip_distance: The distance of the trip is a feature.\npayment_type: The payment method (cash or credit card) is a feature.\nfare_amount: The total taxi fare paid is the label.\nReference:\nhttps://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/predict-prices"
                },
                {
                    "question_number": "33",
                    "question": "You need to predict the sea level in meters for the next 10 years.\nWhich type of machine learning should you use?",
                    "options": [
                        "A. classification",
                        "B. regression",
                        "C. clustering"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": "In the most basic sense, regression refers to prediction of a numeric target.\nLinear regression attempts to establish a linear relationship between one or more independent\nvariables and a numeric outcome, or dependent variable.\nYou use this module to define a linear regression method, and then train a model using a labeled\ndataset. The trained model can then be used to make predictions.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/linear-\nregression\nRegression is a form of machine learning that is used to predict a numeric label based on an item's\nfeatures.\nhttps://docs.microsoft.com/en-us/learn/modules/create-regression-model-azure-machine-learning-\ndesigner/introduction"
                },
                {
                    "question_number": "34",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_29_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_29_img_2.jpg'>\nBox 1: Yes\nAutomated machine learning, also referred to as automated ML or AutoML, is the process of\nautomating the time consuming, iterative tasks of machine learning model development. It allows\ndata scientists, analysts, and developers to build ML models with high scale, efficiency, and\nproductivity all while sustaining model quality.\nBox 2: No\nBox 3: Yes\nDuring training, Azure Machine Learning creates a number of pipelines in parallel that try different\nalgorithms and parameters for you. The service iterates through ML algorithms paired with feature\nselections, where each iteration produces a model with a training score. The higher the score, the\nbetter the model is considered to \"fit\" your dat\na. It will stop once it hits the exit criteria defined in the experiment.\nBox 4: No\nApply automated ML when you want Azure Machine Learning to train and tune a model for you using\nthe target metric you specify.\nThe label is the column you want to predict.\nReference:\nhttps://azure.microsoft.com/en-us/services/machine-learning/automatedml/#features"
                },
                {
                    "question_number": "35",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_30_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "Classification"
                },
                {
                    "question_number": "36",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_31_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_31_img_2.jpg'>\nBox 1: Yes\nIn machine learning, if you have labeled data, that means your data is marked up, or annotated, to\nshow the target, which is the answer you want your machine learning model to predict.\nIn general, data labeling can refer to tasks that include data tagging, annotation, classification,\nmoderation, transcription, or processing.\nBox 2: No\nBox 3: No\nAccuracy is simply the proportion of correctly classified instances. It is usually the first metric you\nlook at when evaluating a classifier. However, when the test data is unbalanced (where most of the\ninstances belong to one of the classes), or you are more interested in the performance on either one\nof the classes, accuracy doesn't really capture the effectiveness of a classifier.\nReference:\nhttps://www.cloudfactory.com/data-labeling-guide\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio/evaluate-model-performance"
                },
                {
                    "question_number": "37",
                    "question": "Which service should you use to extract text, key/value pairs, and table data automatically from\nscanned documents?",
                    "options": [
                        "A. Form Recognizer",
                        "B. Text Analytics",
                        "C. Ink Recognizer",
                        "D. Custom Vision"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": "Accelerate your business processes by automating information extraction. Form Recognizer applies\nadvanced machine learning to accurately extract text, key/value pairs, and tables from documents.\nWith just a few samples, Form Recognizer tailors its understanding to your documents, both on-\npremises and in the cloud. Turn forms into usable data at a fraction of the time and cost, so you can\nfocus more time acting on the information rather than compiling it.\nReference:\nhttps://azure.microsoft.com/en-us/services/cognitive-services/form-recognizer/"
                },
                {
                    "question_number": "38",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_32_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_33_img_1.jpg'>\nAccelerate your business processes by automating information extraction. Form Recognizer applies\nadvanced machine learning to accurately extract text, key/value pairs, and tables from documents.\nWith just a few samples, Form Recognizer tailors its understanding to your documents, both on-\npremises and in the cloud. Turn forms into usable data at a fraction of the time and cost, so you can\nfocus more time acting on the information rather than compiling it.\nReference:\nhttps://azure.microsoft.com/en-us/services/cognitive-services/form-recognizer/"
                },
                {
                    "question_number": "39",
                    "question": "You use Azure Machine Learning designer to publish an inference pipeline.\nWhich two parameters should you use to consume the pipeline? Each correct answer presents part\nof the solution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. the model name",
                        "B. the training endpoint",
                        "C. the authentication key",
                        "D. the REST endpoint"
                    ],
                    "answer": [
                        "C",
                        "D"
                    ],
                    "explanation": "https://docs.microsoft.com/en-in/learn/modules/create-regression-model-azure-machine-learning-\ndesigner/deploy-service"
                },
                {
                    "question_number": "40",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_34_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_34_img_2.jpg'>\nTo perform real-time inferencing, you must deploy a pipeline as a real-time endpoint.\nReal-time endpoints must be deployed to an Azure Kubernetes Service cluster.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-designer#deploy"
                },
                {
                    "question_number": "41",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_35_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_35_img_2.jpg'>\nIn the most basic sense, regression refers to prediction of a numeric target.\nLinear regression attempts to establish a linear relationship between one or more independent\nvariables and a numeric outcome, or dependent variable.\nYou use this module to define a linear regression method, and then train a model using a labeled\ndataset. The trained model can then be used to make predictions.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/algorithm-module-reference/linear-\nregression\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/machine-\nlearning-initialize-model-clustering\nRegression is a form of machine learning that is used to predict a numeric label based on an item's\nfeatures.\nhttps://docs.microsoft.com/en-us/learn/modules/create-regression-model-azure-machine-learning-\ndesigner/introduction"
                },
                {
                    "question_number": "42",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_36_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_37_img_1.jpg'>\nBox 1: Yes\nAzure Machine Learning designer lets you visually connect datasets and modules on an interactive\ncanvas to create machine learning models.\nBox 2: Yes\nWith the designer you can connect the modules to create a pipeline draft.\nAs you edit a pipeline in the designer, your progress is saved as a pipeline draft.\nBox 3: No\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-designer"
                },
                {
                    "question_number": "43",
                    "question": "HOTSPOT\nYou have the following dataset.\n<img src='images/page_38_img_1.jpg'>\nYou plan to use the dataset to train a model that will predict the house price categories of houses.\nWhat are Household Income and House Price Category? To answer, select the appropriate option in\nthe answer area.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_38_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_39_img_1.jpg'>\nBox 1: A feature\nBox 2: A label\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio/interpret-model-results"
                },
                {
                    "question_number": "44",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_40_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_40_img_2.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-designer"
                },
                {
                    "question_number": "45",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_41_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_41_img_2.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-designer-python\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml"
                },
                {
                    "question_number": "46",
                    "question": "A medical research project uses a large anonymized dataset of brain scan images that are categorized\ninto predefined brain haemorrhage types.\nYou need to use machine learning to support early detection of the different brain haemorrhage\ntypes in the images before the images are reviewed by a person.\nThis is an example of which type of machine learning?",
                    "options": [
                        "A. clustering",
                        "B. regression",
                        "C. classification"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": "Reference:\nhttps://docs.microsoft.com/en-us/learn/modules/create-classification-model-azure-machine-\nlearning-designer/introduction"
                },
                {
                    "question_number": "47",
                    "question": "When training a model, why should you randomly split the rows into separate subsets?",
                    "options": [
                        "A. to train the model twice to attain better accuracy",
                        "B. to train multiple models simultaneously to attain better performance",
                        "C. to test the model by using data that was not used to train the model"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": "The goal is to produce a trained (fitted) model that generalizes well to new, unknown data. The fitted\nmodel is evaluated using \u201cnew\u201d examples from the held-out datasets (validation and test datasets) to\nestimate the model's accuracy in classifying new data.\nhttps://en.wikipedia.org/wiki/Training,_validation,_and_test_sets#:~:text=Training%20dataset,-\nA%20training%20dataset&text=The%20goal%20is%20to%20produce,accuracy%20in%20classifying%\n20new%20data."
                },
                {
                    "question_number": "48",
                    "question": "You are evaluating whether to use a basic workspace or an enterprise workspace in Azure Machine\nLearning.\nWhat are two tasks that require an enterprise workspace? Each correct answer presents a complete\nsolution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. Use a graphical user interface (GUI) to run automated machine learning experiments.",
                        "B. Create a compute instance to use as a workstation.",
                        "C. Use a graphical user interface (GUI) to define and run machine learning experiments from Azure\nMachine Learning designer.",
                        "D. Create a dataset from a comma-separated value (CSV) file."
                    ],
                    "answer": [
                        "A",
                        "C"
                    ],
                    "explanation": "Note: Enterprise workspaces are no longer available as of September 2020. The basic workspace now\nhas all the functionality of the enterprise workspace.\nReference:\nhttps://www.azure.cn/en-us/pricing/details/machine-learning/\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace"
                },
                {
                    "question_number": "49",
                    "question": "You need to predict the income range of a given customer by using the following dataset.\n<img src='images/page_43_img_1.jpg'>\nWhich two fields should you use as features? Each correct answer presents a complete solution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. Education Level",
                        "B. Last Name",
                        "C. Age",
                        "D. Income Range",
                        "E. First Name"
                    ],
                    "answer": [
                        "A",
                        "C"
                    ],
                    "explanation": "First Name, Last Name, Age and Education Level are features. Income range is a label (what you want\nto predict). First Name and Last Name are irrelevant in that they have no bearing on income. Age and\nEducation level are the features you should use."
                },
                {
                    "question_number": "50",
                    "question": "You are building a tool that will process images from retail stores and identify the products of\ncompetitors.\nThe solution will use a custom model.\nWhich Azure Cognitive Services service should you use?",
                    "options": [
                        "A. Custom Vision",
                        "B. Form Recognizer",
                        "C. Face",
                        "D. Computer Vision"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": "Reference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/overview"
                },
                {
                    "question_number": "51",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_44_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_45_img_1.jpg'>\nClustering is a machine learning task that is used to group instances of data into clusters that contain\nsimilar characteristics. Clustering can also be used to identify relationships in a dataset\nRegression is a machine learning task that is used to predict the value of the label from a set of\nrelated features.\nReference:\nhttps://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks"
                },
                {
                    "question_number": "52",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_45_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_46_img_1.jpg'>\nBox 1: No\nThe validation dataset is different from the test dataset that is held back from the training of the\nmodel.\nBox 2: Yes\nA validation dataset is a sample of data that is used to give an estimate of model skill while tuning\nmodel\u2019s hyperparameters.\nBox 3: No\nThe Test Dataset, not the validation set, used for this. The Test Dataset is a sample of data used to\nprovide an unbiased evaluation of a final model fit on the training dataset.\nReference:\nhttps://machinelearningmastery.com/difference-test-validation-datasets/"
                },
                {
                    "question_number": "53",
                    "question": "What are two metrics that you can use to evaluate a regression model? Each correct answer presents\na complete solution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. coefficient of determination (R2)",
                        "B. F1 score",
                        "C. root mean squared error (RMSE)",
                        "D. area under curve (AUC)",
                        "E. balanced accuracy"
                    ],
                    "answer": [
                        "A",
                        "C"
                    ],
                    "explanation": "A: R-squared (R2), or Coefficient of determination represents the predictive power of the model as a\nvalue between -inf and 1.00. 1.00 means there is a perfect fit, and the fit can be arbitrarily poor so\nthe scores can be negative.\nC: RMS-loss or Root Mean Squared Error (RMSE) (also called Root Mean Square Deviation, RMSD),\nmeasures the difference between values predicted by a model and the values observed from the\nenvironment that is being modeled.\nReference:\nhttps://docs.microsoft.com/en-us/dotnet/machine-learning/resources/metrics"
                },
                {
                    "question_number": "54",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_47_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_47_img_2.jpg'>\nRegression is a machine learning task that is used to predict the value of the label from a set of\nrelated features.\nReference:\nhttps://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks"
                },
                {
                    "question_number": "55",
                    "question": "DRAG DROP\nYou need to use Azure Machine Learning designer to build a model that will predict automobile\nprices.\nWhich type of modules should you use to complete the model? To answer, drag the appropriate\nmodules to the correct locations. Each module may be used once, more than once, or not at all. You\nmay need to drag the split bar between panes or scroll to view content.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_48_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_49_img_1.jpg'>\nBox 1: Select Columns in Dataset\nFor Columns to be cleaned, choose the columns that contain the missing values you want to change.\nYou can choose multiple columns, but you must use the same replacement method in all selected\ncolumns.\nExample:\n<img src='images/page_50_img_1.jpg'>\nBox 2: Split data\nSplitting data is a common task in machine learning. You will split your data into two separate\ndatasets. One dataset will train the model and the other will test how well the model performed.\nBox 3: Linear regression\nBecause you want to predict price, which is a number, you can use a regression algorithm. For this\nexample, you use a linear regression model.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/tutorial-designer-automobile-price-train-\nscore"
                },
                {
                    "question_number": "56",
                    "question": "Which type of machine learning should you use to identify groups of people who have similar\npurchasing habits?",
                    "options": [
                        "A. classification",
                        "B. regression",
                        "C. clustering"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": "Clustering is a machine learning task that is used to group instances of data into clusters that contain\nsimilar characteristics. Clustering can also be used to identify relationships in a dataset\nReference:\nhttps://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks"
                },
                {
                    "question_number": "57",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_51_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_51_img_2.jpg'>\nRegression is a machine learning task that is used to predict the value of the label from a set of\nrelated features.\nReference:\nhttps://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks"
                },
                {
                    "question_number": "58",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_52_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_52_img_2.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-\nbuild-a-classifier"
                },
                {
                    "question_number": "59",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_52_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_52_img_4.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-\npractices/trusted-ai"
                },
                {
                    "question_number": "60",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_53_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_53_img_2.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/architecture/data-science-process/create-features"
                },
                {
                    "question_number": "61",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_53_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_54_img_1.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-label-data"
                }
            ]
        },
        "topic3": {
            "topic_name": "Describe features of computer vision workloads on Azure",
            "case_study": "",
            "questions": [
                {
                    "question_number": "62",
                    "question": "You need to develop a mobile app for employees to scan and store their expenses while travelling.\nWhich type of computer vision should you use?",
                    "options": [
                        "A. semantic segmentation",
                        "B. image classification",
                        "C. object detection",
                        "D. optical character recognition (OCR)"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": "Azure's Computer Vision API includes Optical Character Recognition (OCR) capabilities that extract\nprinted or handwritten text from images. You can extract text from images, such as photos of license\nplates or containers with serial numbers, as well as from documents - invoices, bills, financial\nreports, articles, and more.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-recognizing-\ntext"
                },
                {
                    "question_number": "63",
                    "question": "DRAG DROP\nMatch the facial recognition tasks to the appropriate questions.\nTo answer, drag the appropriate task from the column on the left to its question on the right. Each\ntask may be used once, more than once, or not at all.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_55_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_55_img_2.jpg'>\nBox 1: verification\nFace verification: Check the likelihood that two faces belong to the same person and receive a\nconfidence score.\nBox 2: similarity\nBox 3: Grouping\nBox 4: identification\nFace detection: Detect one or more human faces along with attributes such as: age, emotion, pose,\nsmile, and facial hair, including 27 landmarks for each face in the image.\nReference:\nhttps://azure.microsoft.com/en-us/services/cognitive-services/face/#features"
                },
                {
                    "question_number": "64",
                    "question": "DRAG DROP\nMatch the types of computer vision to the appropriate scenarios.\nTo answer, drag the appropriate workload type from the column on the left to its scenario on the\nright. Each workload type may be used once, more than once, or not at all.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_56_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "Box 1: Facial recognition\nFace detection that perceives faces and attributes in an image; person identification that matches an\nindividual in your private repository of up to 1 million people; perceived emotion recognition that\ndetects a range of facial expressions like happiness, contempt, neutrality, and fear; and recognition\nand grouping of similar faces in images.\nBox 2: OCR\nBox 3: Objection detection\nObject detection is similar to tagging, but the API returns the bounding box coordinates (in pixels) for\neach object found. For example, if an image contains a dog, cat and person, the Detect operation will\nlist those objects together with their coordinates in the image. You can use this functionality to\nprocess the relationships between the objects in an image. It also lets you determine whether there\nare multiple instances of the same tag in an image.\nThe Detect API applies tags based on the objects or living things identified in the image. There is\ncurrently no formal relationship between the tagging taxonomy and the object detection taxonomy.\nAt a conceptual level, the Detect API only finds objects and living things, while the Tag API can also\ninclude contextual terms like \"indoor\", which can't be localized with bounding boxes.\nReference:\nhttps://azure.microsoft.com/en-us/services/cognitive-services/face/\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-\ndetection"
                },
                {
                    "question_number": "65",
                    "question": "You need to determine the location of cars in an image so that you can estimate the distance\nbetween the cars.\nWhich type of computer vision should you use?",
                    "options": [
                        "A. optical character recognition (OCR)",
                        "B. object detection",
                        "C. image classification",
                        "D. face detection"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "Object detection is similar to tagging, but the API returns the bounding box coordinates (in pixels) for\neach object found. For example, if an image contains a dog, cat and person, the Detect operation will\nlist those objects together with their coordinates in the image. You can use this functionality to\nprocess the relationships between the objects in an image. It also lets you determine whether there\nare multiple instances of the same tag in an image.\nThe Detect API applies tags based on the objects or living things identified in the image. There is\ncurrently no formal relationship between the tagging taxonomy and the object detection taxonomy.\nAt a conceptual level, the Detect API only finds objects and living things, while the Tag API can also\ninclude contextual terms like \"indoor\", which can't be localized with bounding boxes.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-\ndetection"
                },
                {
                    "question_number": "66",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_57_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_58_img_1.jpg'>\nAzure Custom Vision is a cognitive service that lets you build, deploy, and improve your own image\nclassifiers. An image classifier is an AI service that applies labels (which represent classes) to images,\naccording to their visual characteristics. Unlike the Computer Vision service, Custom Vision allows\nyou to specify the labels to apply.\nNote: The Custom Vision service uses a machine learning algorithm to apply labels to images. You,\nthe developer, must submit groups of images that feature and lack the characteristics in question.\nYou label the images yourself at the time of submission. Then the algorithm trains to this data and\ncalculates its own accuracy by testing itself on those same images. Once the algorithm is trained, you\ncan test, retrain, and eventually use it to classify new images according to the needs of your app. You\ncan also export the model itself for offline use.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/home\ncustom vision - This is a type of computer vision service which helps in building/training models\nusing user provided data\nCreating an object detection solution with Custom Vision consists of three main tasks. First you must\nuse upload and tag images, then you can train the model, and finally you must publish the model so\nthat client applications can use it to generate predictions.\nhttps://docs.microsoft.com/en-us/learn/modules/detect-objects-images-custom-vision/2-object-\ndetection-azure"
                },
                {
                    "question_number": "67",
                    "question": "You send an image to a Computer Vision API and receive back the annotated image shown in the\nexhibit.\n<img src='images/page_59_img_1.jpg'>\nWhich type of computer vision was used?",
                    "options": [
                        "A. object detection",
                        "B. semantic segmentation",
                        "C. optical character recognition (OCR)",
                        "D. image classification"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": "Object detection is similar to tagging, but the API returns the bounding box coordinates (in pixels) for\neach object found. For example, if an image contains a dog, cat and person, the Detect operation will\nlist those objects together with their coordinates in the image. You can use this functionality to\nprocess the relationships between the objects in an image. It also lets you determine whether there\nare multiple instances of the same tag in an image.\nThe Detect API applies tags based on the objects or living things identified in the image. There is\ncurrently no formal relationship between the tagging taxonomy and the object detection taxonomy.\nAt a conceptual level, the Detect API only finds objects and living things, while the Tag API can also\ninclude contextual terms like \"indoor\", which can't be localized with bounding boxes.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-\ndetection"
                },
                {
                    "question_number": "68",
                    "question": "What are two tasks that can be performed by using the Computer Vision service? Each correct\nanswer presents a complete solution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. Train a custom image classification model.",
                        "B. Detect faces in an image.",
                        "C. Recognize handwritten text.",
                        "D. Translate the text in an image between languages."
                    ],
                    "answer": [
                        "B",
                        "C"
                    ],
                    "explanation": "B: Azure's Computer Vision service provides developers with access to advanced algorithms that\nprocess images and return information based on the visual features you're interested in. For\nexample, Computer Vision can determine whether an image contains adult content, find specific\nbrands or objects, or find human faces.\nC: Computer Vision includes Optical Character Recognition (OCR) capabilities. You can use the new\nRead API to extract printed and handwritten text from images and documents.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/home\nDetect faces in an image - Face API\nMicrosoft Azure provides multiple cognitive services that you can use to detect and analyze faces,\nincluding:\nComputer Vision, which offers face detection and some basic face analysis, such as determining age.\nVideo Indexer, which you can use to detect and identify faces in a video.\nFace, which offers pre-built algorithms that can detect, recognize, and analyze faces.\nRecognize hand written text - Read API\nThe Read API is a better option for scanned documents that have a lot of text. The Read API also has\nthe ability to automatically determine the proper recognition model"
                },
                {
                    "question_number": "69",
                    "question": "What is a use case for classification?",
                    "options": [
                        "A. predicting how many cups of coffee a person will drink based on how many hours the person slept\nthe previous night.",
                        "B. analyzing the contents of images and grouping images that have similar colors",
                        "C. predicting whether someone uses a bicycle to travel to work based on the distance from home to\nwork",
                        "D. predicting how many minutes it will take someone to run a race based on past race times"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "70",
                    "question": "What are two tasks that can be performed by using computer vision? Each correct answer presents a\ncomplete solution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. Predict stock prices.",
                        "B. Detect brands in an image.",
                        "C. Detect the color scheme in an image",
                        "D. Translate text between languages.",
                        "E. Extract key phrases."
                    ],
                    "answer": [
                        "B",
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "71",
                    "question": "Your company wants to build a recycling machine for bottles. The recycling machine must\nautomatically identify bottles of the correct shape and reject all other items.\nWhich type of AI workload should the company use?",
                    "options": [
                        "A. anomaly detection",
                        "B. conversational AI",
                        "C. computer vision",
                        "D. natural language processing"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": "Azure's Computer Vision service gives you access to advanced algorithms that process images and\nreturn information based on the visual features you're interested in. For example, Computer Vision\ncan determine whether an image contains adult content, find specific brands or objects, or find\nhuman faces.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/overview"
                },
                {
                    "question_number": "72",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_62_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_63_img_1.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/get-started-build-\ndetector"
                },
                {
                    "question_number": "73",
                    "question": "In which two scenarios can you use the Form Recognizer service? Each correct answer presents a\ncomplete solution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. Extract the invoice number from an invoice.",
                        "B. Translate a form from French to English.",
                        "C. Find image of product in a catalog.",
                        "D. Identity the retailer from a receipt."
                    ],
                    "answer": [
                        "A",
                        "D"
                    ],
                    "explanation": "Reference:\nhttps://azure.microsoft.com/en-gb/services/cognitive-services/form-recognizer/#features"
                },
                {
                    "question_number": "74",
                    "question": "HOTSPOT\nYou have a database that contains a list of employees and their photos.\nYou are tagging new photos of the employees.\nFor each of the following statements select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_64_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_64_img_2.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/face/overview\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/face/concepts/face-detection"
                },
                {
                    "question_number": "75",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_65_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_65_img_2.jpg'>\nBox 1: Yes\nCustom Vision functionality can be divided into two features. Image classification applies one or\nmore labels to an image. Object detection is similar, but it also returns the coordinates in the image\nwhere the applied label(s) can be found.\nBox 2: Yes\nThe Custom Vision service uses a machine learning algorithm to analyze images. You, the developer,\nsubmit groups of images that feature and lack the characteristics in question. You label the images\nyourself at the time of submission. Then, the algorithm trains to this data and calculates its own\naccuracy by testing itself on those same images.\nBox 3: No\nCustom Vision service can be used only on graphic files.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/Custom-Vision-Service/overview"
                },
                {
                    "question_number": "76",
                    "question": "You are processing photos of runners in a race.\nYou need to read the numbers on the runners\u2019 shirts to identity the runners in the photos.\nWhich type of computer vision should you use?",
                    "options": [
                        "A. facial recognition",
                        "B. optical character recognition (OCR)",
                        "C. semantic segmentation",
                        "D. object detection"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "Optical character recognition (OCR) allows you to extract printed or handwritten text from images\nand documents.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/overview-ocr"
                },
                {
                    "question_number": "77",
                    "question": "DRAG DROP\nMatch the types of machine learning to the appropriate scenarios.\nTo answer, drag the appropriate machine learning type from the column on the left to its scenario on\nthe right. Each machine learning type may be used once, more than once, or not at all.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_67_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_67_img_2.jpg'>\nBox 1: Image classification\nImage classification is a supervised learning problem: define a set of target classes (objects to\nidentify in images), and train a model to recognize them using labeled example photos.\nBox 2: Object detection\nObject detection is a computer vision problem. While closely related to image classification, object\ndetection performs image classification at a more granular scale. Object detection both locates and\ncategorizes entities within images.\nBox 3: Semantic Segmentation\nSemantic segmentation achieves fine-grained inference by making dense predictions inferring labels\nfor every pixel, so that each pixel is labeled with the class of its enclosing object ore region.\nReference:\nhttps://developers.google.com/machine-learning/practica/image-classification\nhttps://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/object-detection-model-\nbuilder\nhttps://nanonets.com/blog/how-to-do-semantic-segmentation-using-deep-learning/"
                },
                {
                    "question_number": "78",
                    "question": "You need to build an image tagging solution for social media that tags images of your friends\nautomatically. Which Azure Cognitive Services service should you use?",
                    "options": [
                        "A. Computer Vision",
                        "B. Face",
                        "C. Text Analytics",
                        "D. Form Recognizer"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                }
            ]
        },
        "topic4": {
            "topic_name": "Describe features of Natural Language Processing (NLP) workloads on Azure",
            "case_study": "",
            "questions": [
                {
                    "question_number": "79",
                    "question": "Your website has a chatbot to assist customers.\nYou need to detect when a customer is upset based on what the customer types in the chatbot.\nWhich type of AI workload should you use?",
                    "options": [
                        "A. anomaly detection",
                        "B. semantic segmentation",
                        "C. regression",
                        "D. natural language processing"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": "Natural language processing (NLP) is used for tasks such as sentiment analysis, topic detection,\nlanguage detection, key phrase extraction, and document categorization.\nSentiment Analysis is the process of determining whether a piece of writing is positive, negative or\nneutral.\nReference:\nhttps://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-\nlanguage-processing"
                },
                {
                    "question_number": "80",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_69_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_69_img_2.jpg'>\nNatural language processing (NLP) is used for tasks such as sentiment analysis, topic detection,\nlanguage detection, key phrase extraction, and document categorization.\nReference:\nhttps://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-\nlanguage-processing"
                },
                {
                    "question_number": "81",
                    "question": "Which AI service can you use to interpret the meaning of a user input such as \u201cCall me back later?\u201d",
                    "options": [
                        "A. Translator Text",
                        "B. Text Analytics",
                        "C. Speech",
                        "D. Language Understanding (LUIS)"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": "https://docs.microsoft.com/en-us/azure/cognitive-services/luis/what-is-luis"
                },
                {
                    "question_number": "82",
                    "question": "You are developing a Chabot solution in Azure.\nWhich service should you use to determine a user\u2019s intent?",
                    "options": [
                        "A. Translator",
                        "B. Azure Cognitive Search",
                        "C. Speech",
                        "D. Language"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "Language Understanding (LUIS) is a cloud-based API service that applies custom machine-learning\nintelligence to a user's conversational, natural language text to predict overall meaning, and pull out\nrelevant, detailed information.\nDesign your LUIS model with categories of user intentions called intents. Each intent needs examples\nof user utterances. Each utterance can provide data that needs to be extracted with machine-\nlearning entities.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/luis/what-is-luis"
                },
                {
                    "question_number": "83",
                    "question": "You need to make the press releases of your company available in a range of languages.\nWhich service should you use?",
                    "options": [
                        "A. Translator Text",
                        "B. Text Analytics",
                        "C. Speech",
                        "D. Language Understanding (LUIS)"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": "Press release is a written communication. Speech wouldn't make sense. Plus, the Speech service\ndoesn't translate languages, it \"translates\" audio into text, and vice versa.\nhttps://docs.microsoft.com/en-us/learn/modules/translate-text-with-translation-service/2-get-\nstarted-azure"
                },
                {
                    "question_number": "84",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_71_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_72_img_1.jpg'>\nThe Text Analytics API is a cloud-based service that provides advanced natural language processing\nover raw text, and includes four main functions: sentiment analysis, key phrase extraction, named\nentity recognition, and language detection.\nBox 1: Yes\nYou can detect which language the input text is written in and report a single language code for every\ndocument submitted on the request in a wide range of languages, variants, dialects, and some\nregional/cultural languages. The language code is paired with a score indicating the strength of the\nscore.\nBox 2: No\nBox 3: Yes\nNamed Entity Recognition: Identify and categorize entities in your text as people, places,\norganizations, date/time, quantities, percentages, currencies, and more. Well-known entities are\nalso recognized and linked to more information on the web.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/overview"
                },
                {
                    "question_number": "85",
                    "question": "DRAG DROP\nMatch the types of natural languages processing workloads to the appropriate scenarios.\nTo answer, drag the appropriate workload type from the column on the left to its scenario on the\nright. Each workload type may be used once, more than once, or not at all.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_73_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "Box 1: Entity recognition\nClassify a broad range of entities in text, such as people, places, organisations, date/time and\npercentages, using named entity recognition. Whereas:- Get a list of relevant phrases that best\ndescribe the subject of each record using key phrase extraction.\nBox 2: Sentiment analysis\nSentiment Analysis is the process of determining whether a piece of writing is positive, negative or\nneutral.\nBox 3: Translation\nUsing Microsoft\u2019s Translator text API\nThis versatile API from Microsoft can be used for the following:\nTranslate text from one language to another.\nTransliterate text from one script to another.\nDetecting language of the input text.\nFind alternate translations to specific text.\nDetermine the sentence length.\nReference:\nhttps://azure.microsoft.com/en-us/services/cognitive-services/text-analytics"
                },
                {
                    "question_number": "86",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_74_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_74_img_2.jpg'>\nBox 1: Yes\nContent Moderator is part of Microsoft Cognitive Services allowing businesses to use machine\nassisted moderation of text, images, and videos that augment human review.\nThe text moderation capability now includes a new machine-learning based text classification feature\nwhich uses a trained model to identify possible abusive, derogatory or discriminatory language such\nas slang, abbreviated words, offensive, and intentionally misspelled words for review.\nBox 2: No\nAzure's Computer Vision service gives you access to advanced algorithms that process images and\nreturn information based on the visual features you're interested in. For example, Computer Vision\ncan determine whether an image contains adult content, find specific brands or objects, or find\nhuman faces.\nBox 3: Yes\nNatural language processing (NLP) is used for tasks such as sentiment analysis, topic detection,\nlanguage detection, key phrase extraction, and document categorization.\nSentiment Analysis is the process of determining whether a piece of writing is positive, negative or\nneutral.\nReference:\nhttps://azure.microsoft.com/es-es/blog/machine-assisted-text-classification-on-content-moderator-\npublic-preview/\nhttps://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-\nlanguage-processing"
                },
                {
                    "question_number": "87",
                    "question": "You are developing a natural language processing solution in Azure. The solution will analyze\ncustomer reviews and determine how positive or negative each review is.\nThis is an example of which type of natural language processing workload?",
                    "options": [
                        "A. language detection",
                        "B. sentiment analysis",
                        "C. key phrase extraction",
                        "D. entity recognition"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "Sentiment Analysis is the process of determining whether a piece of writing is positive, negative or\nneutral.\nReference:\nhttps://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-\nlanguage-processing"
                },
                {
                    "question_number": "88",
                    "question": "You use natural language processing to process text from a Microsoft news story.\nYou receive the output shown in the following exhibit.\n<img src='images/page_76_img_1.jpg'>\nWhich type of natural languages processing was performed?",
                    "options": [
                        "A. entity recognition",
                        "B. key phrase extraction",
                        "C. sentiment analysis",
                        "D. translation"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": "https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/overview\nYou can provide the Text Analytics service with unstructured text and it will return a list of entities in\nthe text that it recognizes. You can provide the Text Analytics service with unstructured text and it\nwill return a list of entities in the text that it recognizes. The service can also provide links to more\ninformation about that entity on the web. An entity is essentially an item of a particular type or a\ncategory; and in some cases, subtype, such as those as shown in the following table.\nhttps://docs.microsoft.com/en-us/learn/modules/analyze-text-with-text-analytics-service/2-get-\nstarted-azure"
                },
                {
                    "question_number": "89",
                    "question": "DRAG DROP\nYou plan to apply Text Analytics API features to a technical support ticketing system.\nMatch the Text Analytics API features to the appropriate natural language processing scenarios.\nTo answer, drag the appropriate feature from the column on the left to its scenario on the right. Each\nfeature may be used once, more than once, or not at all.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_77_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_77_img_2.jpg'>\nBox1: Sentiment analysis\nSentiment Analysis is the process of determining whether a piece of writing is positive, negative or\nneutral.\nBox 2: Broad entity extraction\nBroad entity extraction: Identify important concepts in text, including key\nKey phrase extraction/ Broad entity extraction: Identify important concepts in text, including key\nphrases and named entities such as people, places, and organizations.\nBox 3: Entity Recognition\nNamed Entity Recognition: Identify and categorize entities in your text as people, places,\norganizations, date/time, quantities, percentages, currencies, and more. Well-known entities are\nalso recognized and linked to more information on the web.\nReference:\nhttps://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-\nlanguage-processing\nhttps://azure.microsoft.com/en-us/services/cognitive-services/text-analytics"
                },
                {
                    "question_number": "90",
                    "question": "You are developing a solution that uses the Text Analytics service.\nYou need to identify the main talking points in a collection of documents.\nWhich type of natural language processing should you use?",
                    "options": [
                        "A. entity recognition",
                        "B. key phrase extraction",
                        "C. sentiment analysis",
                        "D. language detection"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "Broad entity extraction: Identify important concepts in text, including key\nKey phrase extraction/ Broad entity extraction: Identify important concepts in text, including key\nphrases and named entities such as people, places, and organizations.\nReference:\nhttps://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-\nlanguage-processing"
                },
                {
                    "question_number": "91",
                    "question": "In which two scenarios can you use speech recognition? Each correct answer presents a complete\nsolution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. an in-car system that reads text messages aloud",
                        "B. providing closed captions for recorded or live videos",
                        "C. creating an automated public address system for a train station",
                        "D. creating a transcript of a telephone call or meeting"
                    ],
                    "answer": [
                        "B",
                        "D"
                    ],
                    "explanation": "Reference:\nhttps://azure.microsoft.com/en-gb/services/cognitive-services/speech-to-text/#features"
                },
                {
                    "question_number": "92",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_79_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_79_img_2.jpg'>\nReference:\nhttps://azure.microsoft.com/en-gb/services/cognitive-services/speech-to-text/#features\nSpeech recognition means Speech to Text. In the above example as a person speaks the words are\nconverted into text of the same language. Hence Speech to Text also called Speech recognition is the\nright answer.\nSpeech recognition - the ability to detect and interpret spoken input.\nSpeech synthesis - the ability to generate spoken output.\nhttps://docs.microsoft.com/en-us/learn/modules/recognize-synthesize-speech/1-introduction"
                },
                {
                    "question_number": "93",
                    "question": "You need to build an app that will read recipe instructions aloud to support users who have reduced\nvision.\nWhich version service should you use?",
                    "options": [
                        "A. Text Analytics",
                        "B. Translator Text",
                        "C. Speech",
                        "D. Language Understanding (LUIS)"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": "Reference:\nhttps://azure.microsoft.com/en-us/services/cognitive-services/text-to-speech/#features"
                },
                {
                    "question_number": "94",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_81_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_81_img_2.jpg'>\nReference:\nhttps://docs.microsoft.com/en-gb/azure/cognitive-services/text-analytics/overview\nhttps://azure.microsoft.com/en-gb/services/cognitive-services/speech-services/\nYou can use the Speech service to transcribe a call to text - Yes we can use Speech to Text API to\nachieve this\nhttps://docs.microsoft.com/en-us/learn/modules/recognize-synthesize-speech/1-introduction\nYou can use a speech service to translate the audio of a call to a different language - Yes we can use\nSpeech translation service to achieve this\nThe Speech service includes the following application programming interfaces (APIs):\nSpeech-to-text - used to transcribe speech from an audio source to text format.\nText-to-speech - used to generate spoken audio from a text source.\nSpeech Translation - used to translate speech in one language to text or speech in another.\nhttps://docs.microsoft.com/en-us/learn/modules/translate-text-with-translation-service/2-get-\nstarted-azure\nYou can use text analytics service to extract key entities from a call transcript -Yes Text Analytics API\nhelps to achieve this\nhttps://docs.microsoft.com/en-us/learn/modules/analyze-text-with-text-analytics-service/2-get-\nstarted-azure"
                },
                {
                    "question_number": "95",
                    "question": "You plan to develop a bot that will enable users to query a knowledge base by using natural language\nprocessing.\nWhich two services should you include in the solution? Each correct answer presents part of the\nsolution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. Language Service",
                        "B. Azure Bot Service",
                        "C. Form Recognizer",
                        "D. Anomaly Detector"
                    ],
                    "answer": [
                        "A",
                        "D"
                    ],
                    "explanation": "Reference:\nhttps://docs.microsoft.com/en-us/azure/bot-service/bot-service-overview-introduction?view=azure-\nbot-service-4.0\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/luis/choose-natural-language-\nprocessing-service"
                },
                {
                    "question_number": "96",
                    "question": "In which two scenarios can you use a speech synthesis solution? Each correct answer presents a\ncomplete solution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. an automated voice that reads back a credit card number entered into a telephone by using a\nnumeric keypad",
                        "B. generating live captions for a news broadcast",
                        "C. extracting key phrases from the audio recording of a meeting",
                        "D. an Al character in a computer game that speaks audibly to a player"
                    ],
                    "answer": [
                        "A",
                        "D"
                    ],
                    "explanation": "Azure Text to Speech is a Speech service feature that converts text to lifelike speech.\nReference:\nhttps://azure.microsoft.com/en-in/services/cognitive-services/text-to-speech/"
                },
                {
                    "question_number": "97",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_83_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_84_img_1.jpg'>\nThe translator service provides multi-language support for text translation, transliteration, language\ndetection, and dictionaries.\nSpeech-to-Text, also known as automatic speech recognition (ASR), is a feature of Speech Services\nthat provides transcription.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/Translator/translator-info-overview\nhttps://docs.microsoft.com/en-us/legal/cognitive-services/speech-service/speech-to-\ntext/transparency-note"
                },
                {
                    "question_number": "98",
                    "question": "DRAG DROP\nYou need to scan the news for articles about your customers and alert employees when there is a\nnegative article. Positive articles must be added to a press book.\nWhich natural language processing tasks should you use to complete the process? To answer, drag\nthe appropriate tasks to the correct locations. Each task may be used once, more than once, or not at\nall. You may need to drag the split bar between panes or scroll to view content.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_85_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_85_img_2.jpg'>\nBox 1: Entity recognition\nthe Named Entity Recognition module in Machine Learning Studio (classic), to identify the names of\nthings, such as people, companies, or locations in a column of text.\nNamed entity recognition is an important area of research in machine learning and natural language\nprocessing (NLP), because it can be used to answer many real-world questions, such as:\nWhich companies were mentioned in a news article?\nDoes a tweet contain the name of a person? Does the tweet also provide his current location?\nWere specified products mentioned in complaints or reviews?\nBox 2: Sentiment Analysis\nThe Text Analytics API's Sentiment Analysis feature provides two ways for detecting positive and\nnegative sentiment. If you send a Sentiment Analysis request, the API will return sentiment labels\n(such as \"negative\", \"neutral\" and \"positive\") and confidence scores at the sentence and document-\nlevel.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/named-entity-\nrecognition\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/how-tos/text-analytics-\nhow-to-sentiment-analysis"
                },
                {
                    "question_number": "99",
                    "question": "In which scenario should you use key phrase extraction?",
                    "options": [
                        "A. translating a set of documents from English to German",
                        "B. generating captions for a video based on the audio track",
                        "C. identifying whether reviews of a restaurant are positive or negative",
                        "D. identifying which documents provide information about the same topics"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "100",
                    "question": "You have insurance claim reports that are stored as text.\nYou need to extract key terms from the reports to generate summaries.\nWhich type of Al workload should you use?\nconversational Al\nanomaly detection\nnatural language processing\ncomputer vision",
                    "options": [
                        "A. conversational Al\nB.\nanomaly detection\nC.\nnatural language processing\nD.\ncomputer vision"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": "Key phrase extraction is the concept of evaluating the text of a document, or documents, and then\nidentifying the main talking points of the document(s).\nKey phase extraction is a part of Text Analytics. The Text Analytics service is a part of the Azure\nCognitive Services offerings that can perform advanced natural language processing over raw text.\nhttps://docs.microsoft.com/en-us/learn/modules/analyze-text-with-text-analytics-service/2-get-\nstarted-azure"
                },
                {
                    "question_number": "101",
                    "question": "You are authoring a Language Understanding (LUIS) application to support a music festival.\nYou want users to be able to ask questions about scheduled shows, such as: \u201cWhich act is playing on\nthe main stage?\u201d\nThe question \u201cWhich act is playing on the main stage?\u201d is an example of which type of element?",
                    "options": [
                        "A. an intent",
                        "B. an utterance",
                        "C. a domain",
                        "D. an entity"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "Utterances are input from the user that your app needs to interpret.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/LUIS/luis-concept-utterance"
                },
                {
                    "question_number": "102",
                    "question": "You build a QnA Maker bot by using a frequently asked questions (FAQ) page.\nYou need to add professional greetings and other responses to make the bot more user friendly.\nWhat should you do?",
                    "options": [
                        "A. Increase the confidence threshold of responses",
                        "B. Enable active learning",
                        "C. Create multi-turn questions",
                        "D. Add chit-chat"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": "Reference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/how-to/chit-chat-knowledge-\nbase?tabs=v1"
                },
                {
                    "question_number": "103",
                    "question": "You need to develop a chatbot for a website. The chatbot must answer users\u2019 questions based on the\ninformation in the following documents:\nA product troubleshooting guide in a Microsoft Word document\nA frequently asked questions (FAQ) list on a webpage\nWhich service should you use to process the documents?",
                    "options": [
                        "A. Azure Bot Service",
                        "B. Language Understanding",
                        "C. Text Analytics",
                        "D. QnA Maker"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": "Reference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/QnAMaker/Overview/overview"
                },
                {
                    "question_number": "104",
                    "question": "You are building a Language Understanding model for an e-commerce business.\nYou need to ensure that the model detects when utterances are outside the intended scope of the\nmodel.\nWhat should you do?",
                    "options": [
                        "A. Test the model by using new utterances",
                        "B. Add utterances to the None intent",
                        "C. Create a prebuilt task entity",
                        "D. Create a new model"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "The\u00a0None\u00a0intent is filled with utterances that are outside of your domain.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/LUIS/luis-concept-intent"
                }
            ]
        },
        "topic5": {
            "topic_name": "Describe features of conversational AI workloads on Azure",
            "case_study": "",
            "questions": [
                {
                    "question_number": "105",
                    "question": "Which two scenarios are examples of a conversational AI workload? Each correct answer presents a\ncomplete solution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. a telephone answering service that has a pre-recorder message",
                        "B. a chatbot that provides users with the ability to find answers on a website by themselves",
                        "C. telephone voice menus to reduce the load on human resources",
                        "D. a service that creates frequently asked questions (FAQ) documents by crawling public websites"
                    ],
                    "answer": [
                        "B",
                        "C"
                    ],
                    "explanation": "B: A bot is an automated software program designed to perform a particular task. Think of it as a\nrobot without a body.\nC: Automated customer interaction is essential to a business of any size. In fact, 61% of consumers\nprefer to communicate via speech, and most of them prefer self-service. Because customer\nsatisfaction is a priority for all businesses, self-service is a critical facet of any customer-facing\ncommunications strategy.\nReference:\nhttps://docs.microsoft.com/en-us/azure/architecture/data-guide/big-data/ai-overview\nhttps://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/interactive-voice-\nresponse-bot"
                },
                {
                    "question_number": "106",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_89_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_90_img_1.jpg'>\nBox 1: Yes\nAzure bot service can be integrated with the powerful AI capabilities with Azure Cognitive Services.\nBox 2: Yes\nAzure bot service engages with customers in a conversational manner.\nBox 3: No\nThe QnA Maker service creates knowledge base, not question and answers sets.\nNote: You can use the QnA Maker service and a knowledge base to add question-and-answer support\nto your bot. When you create your knowledge base, you seed it with questions and answers.\nReference:\nhttps://docs.microsoft.com/en-us/azure/bot-service/bot-builder-tutorial-add-qna"
                },
                {
                    "question_number": "107",
                    "question": "You need to provide content for a business chatbot that will help answer simple user queries.\nWhat are three ways to create question and answer text by using QnA Maker? Each correct answer\npresents a complete solution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. Generate the questions and answers from an existing webpage.",
                        "B. Use automated machine learning to train a model based on a file that contains the questions.",
                        "C. Manually enter the questions and answers.",
                        "D. Connect the bot to the Cortana channel and ask questions by using Cortana.",
                        "E. Import chit-chat content from a predefined data source."
                    ],
                    "answer": [
                        "A",
                        "C",
                        "E"
                    ],
                    "explanation": "Automatic extraction\nExtract question-answer pairs from semi-structured content, including FAQ pages, support websites,\nexcel files, SharePoint documents, product manuals and policies.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/concepts/content-types"
                },
                {
                    "question_number": "108",
                    "question": "You have a frequently asked questions (FAQ) PDF file.\nYou need to create a conversational support system based on the FAQ.\nWhich service should you use?",
                    "options": [
                        "A. QnA Maker",
                        "B. Text Analytics",
                        "C. Computer Vision",
                        "D. Language Understanding (LUIS)"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": "QnA Maker is a cloud-based API service that lets you create a conversational question-and-answer\nlayer over your existing data. Use it to build a knowledge base by extracting questions and answers\nfrom your semi-structured content, including FAQs, manuals, and documents.\nReference:\nhttps://azure.microsoft.com/en-us/services/cognitive-services/qna-maker/"
                },
                {
                    "question_number": "109",
                    "question": "You need to reduce the load on telephone operators by implementing a chatbot to answer simple\nquestions with predefined answers.\nWhich two AI service should you use to achieve the goal? Each correct answer presents part of the\nsolution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. Text Analytics",
                        "B. QnA Maker",
                        "C. Azure Bot Service",
                        "D. Translator Text"
                    ],
                    "answer": [
                        "B",
                        "C"
                    ],
                    "explanation": "Bots are a popular way to provide support through multiple communication channels. You can use\nthe QnA\nMaker service and Azure Bot Service to create a bot that answers user questions.\nReference:\nhttps://docs.microsoft.com/en-us/learn/modules/build-faq-chatbot-qna-maker-azure-bot-service/"
                },
                {
                    "question_number": "111",
                    "question": "You have the process shown in the following exhibit.\n<img src='images/page_92_img_1.jpg'>\nWhich type AI solution is shown in the diagram?",
                    "options": [
                        "A. a sentiment analysis solution",
                        "B. a chatbot",
                        "C. a machine learning model",
                        "D. a computer vision application"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "112",
                    "question": "You need to develop a web-based AI solution for a customer support system. Users must be able to\ninteract with a web app that will guide them to the best resource or answer.\nWhich service should you use?",
                    "options": [
                        "A. Custom Vision",
                        "B. QnA Maker",
                        "C. Translator Text",
                        "D. Face"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "QnA Maker is a cloud-based API service that lets you create a conversational question-and-answer\nlayer over your existing data. Use it to build a knowledge base by extracting questions and answers\nfrom your semistructured content, including FAQs, manuals, and documents. Answer users\u2019\nquestions with the best answers from the QnAs in your knowledge base\u2014automatically. Your\nknowledge base gets smarter, too, as it\ncontinually learns from user behavior.\nIncorrect Answers:\nA: Azure Custom Vision is a cognitive service that lets you build, deploy, and improve your own\nimage\nclassifiers. An image classifier is an AI service that applies labels (which represent classes) to images,\naccording to their visual characteristics. Unlike the Computer Vision service, Custom Vision allows\nyou to\nspecify the labels to apply.\nD: Azure Cognitive Services Face Detection API: At a minimum, each detected face corresponds to a\nfaceRectangle field in the response. This set of pixel coordinates for the left, top, width, and height\nmark the\nlocated face. Using these coordinates, you can get the location of the face and its size. In the API\nresponse,\nfaces are listed in size order from largest to smallest.\nReference:\nhttps://azure.microsoft.com/en-us/services/cognitive-services/qna-maker/"
                },
                {
                    "question_number": "113",
                    "question": "Which AI service should you use to create a bot from a frequently asked questions (FAQ) document?",
                    "options": [
                        "A. QnA Maker",
                        "B. Language Understanding (LUIS)",
                        "C. Text Analytics",
                        "D. Speech"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "114",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_94_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_94_img_2.jpg'>\nWith Microsoft\u2019s Conversational AI tools developers can build, connect, deploy, and manage\nintelligent bots that naturally interact with their users on a website, app, Cortana, Microsoft Teams,\nSkype, Facebook Messenger, Slack, and more.\nReference:\nhttps://azure.microsoft.com/en-in/blog/microsoft-conversational-ai-tools-enable-developers-to-\nbuild-connect-and-manage-intelligent-bots"
                },
                {
                    "question_number": "115",
                    "question": "Which scenario is an example of a webchat bot?",
                    "options": [
                        "A. Determine whether reviews entered on a website for a concert are positive or negative, and then\nadd a\nthumbs up or thumbs down emoji to the reviews.",
                        "B. Translate into English questions entered by customers at a kiosk so that the appropriate person\ncan call the customers back.",
                        "C. Accept questions through email, and then route the email messages to the correct person based\non the content of the message.",
                        "D. From a website interface, answer common questions about scheduled events and ticket purchases\nfor a music festival."
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "116",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_95_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_96_img_1.jpg'>\nReference:\nhttps://docs.microsoft.com/en-gb/azure/cognitive-services/qnamaker/concepts/data-sources-and-\ncontent\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/luis/choose-natural-language-\nprocessing-service\nQnA maker conversational AI service and has nothing to do with SQL database\nYou can easily create a user support bot solution on Microsoft Azure using a combination of two core\ntechnologies:\n- QnA Maker. This cognitive service enables you to create and publish a knowledge base with built-in\nnatural language processing capabilities.\n- Azure Bot Service. This service provides a framework for developing, publishing, and managing bots\non Azure.\nhttps://docs.microsoft.com/en-us/learn/modules/build-faq-chatbot-qna-maker-azure-bot-service/2-\nget-started-qna-bot\nLUIS is used to understand user intent from utterances.\nCreating a language understanding application with Language Understanding consists of two main\ntasks. First you must define entities, intents, and utterances with which to train the language model -\nreferred to as authoring the model. Then you must publish the model so that client applications can\nuse it for intent and entity prediction based on user input.\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/luis/choose-natural-language-\nprocessing-service"
                },
                {
                    "question_number": "117",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_97_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_97_img_2.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/bot-service/bot-service-manage-channels?view=azure-bot-\nservice-4.0\nAll 3 are correct as they are the different channels to connect with a bot\nOffice 365 email - Enable a bot to communicate with users via Office 365 email.\nMicrosoft Teams - Configure a bot to communicate with users through Microsoft Teams.\nWeb Chat - Automatically configured for you when you create a bot with the Bot Framework Service.\nhttps://docs.microsoft.com/en-us/azure/bot-service/bot-service-manage-channels?view=azure-bot-\nservice-4.0"
                },
                {
                    "question_number": "118",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_98_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_98_img_2.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/bot-service/bot-service-overview-introduction?view=azure-\nbot-service-4.0"
                },
                {
                    "question_number": "119",
                    "question": "You have a webchat bot that provides responses from a QnA Maker knowledge base.\nYou need to ensure that the bot uses user feedback to improve the relevance of the responses over\ntime.\nWhat should you use?",
                    "options": [
                        "A. key phrase extraction",
                        "B. sentiment analysis",
                        "C. business logic",
                        "D. active learning"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": "Reference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/how-to/improve-knowledge-\nbase"
                },
                {
                    "question_number": "120",
                    "question": "You are developing a conversational AI solution that will communicate with users through multiple\nchannels including email, Microsoft Teams, and webchat.\nWhich service should you use?",
                    "options": [
                        "A. Text Analytics",
                        "B. Azure Bot Service",
                        "C. Translator",
                        "D. Form Recognizer"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": "Reference:\nhttps://docs.microsoft.com/en-us/azure/bot-service/bot-service-overview-introduction?view=azure-\nbot-service-4.0"
                },
                {
                    "question_number": "121",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_99_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_100_img_1.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/bot-service/bot-service-overview-introduction?view=azure-\nbot-service-4.0"
                },
                {
                    "question_number": "122",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_100_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_101_img_1.jpg'>"
                },
                {
                    "question_number": "123",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_101_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_101_img_3.jpg'>"
                },
                {
                    "question_number": "124",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_102_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_102_img_2.jpg'>"
                },
                {
                    "question_number": "125",
                    "question": "To complete the sentence, select the appropriate option in the answer area.\nComputer vision capabilities can be Deployed to\u2026\u2026\u2026\u2026\u2026\u2026..",
                    "options": [],
                    "answer": [],
                    "explanation": "Integrate a facial recognition feature into an app.\n<img src='images/page_102_img_3.jpg'>"
                },
                {
                    "question_number": "126",
                    "question": "You need to track multiple versions of a model that was trained by using Azure Machine Learning.\nWhat should you do?",
                    "options": [
                        "A. Provision an inference duster.",
                        "B. Explain the model.",
                        "C. Register the model.",
                        "D. Register the training data."
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "127",
                    "question": "You need to develop a chatbot for a website. The chatbot must answer users questions based on the\ninformation m the following documents\n\u2022 A product troubleshooting guide m a Microsoft Word document\n\u2022 A frequently asked questions (FAQ) list on a webpage\nWhich service should you use to process the documents?",
                    "options": [
                        "A. Language Undemanding",
                        "B. Text Analytics",
                        "C. Azure Bot Service",
                        "D. QnA Maker"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "128",
                    "question": "You are building a knowledge base by using QnA Maker. Which file format can you use to populate\nthe knowledge base?",
                    "options": [
                        "A. PDF",
                        "B. PPTX",
                        "C. XML",
                        "D. ZIP"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": "Reference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/concepts/data-sources-and-\ncontent"
                },
                {
                    "question_number": "129",
                    "question": "You use Azure Machine Learning designer to build a model pipeline. What should you create before\nyou can run the pipeline?\na Jupyter notebook\na registered model\na compute resource",
                    "options": [
                        "A. a Jupyter notebook\nB.\na registered model\nC.\na compute resource"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "130",
                    "question": "You use drones to identify where weeds grow between rows of crops to send an Instruction for the\nremoval of the weeds. This is an example of which type of computer vision?",
                    "options": [
                        "A. scene segmentation",
                        "B. optical character recognition (OCR)",
                        "C. object detection"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": "Object detection is similar to tagging, but the API returns the bounding box coordinates for each tag\napplied. For example, if an image contains a dog, cat and person, the Detect operation will list those\nobjects together with their coordinates in the image.\nReference:\nhttps://docs.microsoft.com/en-us/ai-builder/object-detection-overview\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/overview-ocr\nhttps://docs.microsoft.com/en-us/azure/azure-video-analyzer/video-analyzer-for-media-docs/video-\nindexer-overview"
                },
                {
                    "question_number": "131",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_105_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_105_img_2.jpg'>"
                },
                {
                    "question_number": "132",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_105_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_106_img_1.jpg'>"
                },
                {
                    "question_number": "133",
                    "question": "DRAG DROP\nMatch the services to the appropriate descriptions.\nTo answer, drag the appropriate service from the column on the left to its description on the right.\nEach service may be used once, more than once, or not at all.\nNOTE: Each correct match is worth one point\n<img src='images/page_106_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_106_img_3.jpg'>\n."
                },
                {
                    "question_number": "134",
                    "question": "DRAG DROP\nMatch the principles of responsible AI to the appropriate descriptions.\nTo answer, drag the appropriate principle from the column on the left to its description on the right.\nEach principle may be used once, more than once, or not at all.\nNOTE: Each correct match is worth one point.\n<img src='images/page_107_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_107_img_2.jpg'>"
                },
                {
                    "question_number": "135",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_107_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_108_img_1.jpg'>"
                },
                {
                    "question_number": "136",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_108_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_108_img_3.jpg'>"
                },
                {
                    "question_number": "137",
                    "question": "To complete the sentence, select the appropriate option in the answer area.\nUsing Recency, Frequency, and Monetary (RFM) values to identify segments of a customer base is an\nexample of___________",
                    "options": [],
                    "answer": [],
                    "explanation": "Classification\n<img src='images/page_109_img_1.jpg'>"
                },
                {
                    "question_number": "138",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_109_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_109_img_3.jpg'>\nReference:\nhttps://docs.microsoft.com/en-us/azure/architecture/reference-architectures/ai/conversational-bot\nhttps://docs.microsoft.com/en-us/azure/bot-service/bot-builder-webchat-overview?view=azure-\nbot-service-4.0"
                },
                {
                    "question_number": "139",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_110_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_110_img_2.jpg'>"
                },
                {
                    "question_number": "140",
                    "question": "HOTSPOT\nYou have an Azure Machine Learning model that predicts product quality. The model has a training\ndataset that contains 50,000 records. A sample of the data is shown in the following table.\n<img src='images/page_110_img_3.jpg'>\nFor each of the following Statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_110_img_4.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_111_img_1.jpg'>"
                },
                {
                    "question_number": "141",
                    "question": "HOTSPOT\ncorrectly completes the sentence.\n<img src='images/page_111_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_111_img_3.jpg'>"
                },
                {
                    "question_number": "142",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_111_img_4.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_111_img_5.jpg'>"
                },
                {
                    "question_number": "143",
                    "question": "DRAG DROP\nMatch the tool to the Azure Machine Learning task.\nTo answer, drag the appropriate tool from the column on the left to its tasks on the right. Each tool\nmay be used once, more than once, or not at all\nNOTE: Each correct match is worth one point.\n<img src='images/page_112_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_112_img_2.jpg'>"
                },
                {
                    "question_number": "144",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_112_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_112_img_4.jpg'>"
                },
                {
                    "question_number": "145",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_112_img_5.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_112_img_6.jpg'>"
                },
                {
                    "question_number": "146",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_113_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_113_img_2.jpg'>"
                },
                {
                    "question_number": "147",
                    "question": "You have an Azure Machine Learning pipeline that contains a Split Data module. The Split Data\nmodule outputs to a Train Model module and a Score Model module. What is the function of the\nSplit Data module?",
                    "options": [
                        "A. selecting columns that must be included in the model",
                        "B. creating training and validation datasets",
                        "C. diverting records that have missing data",
                        "D. scaling numeric variables so that they are within a consistent numeric range"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "148",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_113_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_113_img_4.jpg'>"
                },
                {
                    "question_number": "149",
                    "question": "You need to create a customer support solution to help customers access information. The solution\nmust support email, phone, and live chat channels. Which type of Al solution should you use?",
                    "options": [
                        "A. natural language processing (NLP)",
                        "B. computer vision",
                        "C. machine learning",
                        "D. chatbot"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "150",
                    "question": "You are building a chatbot that will use natural language processing (NLP) to perform the following\nactions based on the text input of a user:\n\u2022 Accept customer orders.\n\u2022 Retrieve support documents.\n\u2022 Retrieve order status updates.\nWhich type of NLP should you use?",
                    "options": [
                        "A. sentiment analysis",
                        "B. translation",
                        "C. language modeling",
                        "D. named entity recognition"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "151",
                    "question": "DRAG DROP\nMatch the Azure Cognitive Services service to the appropriate actions.\nTo answer, drag the appropriate service from the column on the left to its action on the right. Each\nservice may he used once, more than once, or not at all.\nNOTE: Each correct match is worth one point.\n<img src='images/page_114_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_115_img_1.jpg'>"
                },
                {
                    "question_number": "152",
                    "question": "HOTSPOT\nbrectly completes the sentence.\n<img src='images/page_115_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_115_img_3.jpg'>"
                },
                {
                    "question_number": "153",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes If the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_115_img_4.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_115_img_5.jpg'>"
                },
                {
                    "question_number": "154",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_116_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_116_img_2.jpg'>"
                },
                {
                    "question_number": "155",
                    "question": "You have an Al solution that provides users with the ability to control smart devices by using verbal\ncommands.\nWhich two types of natural language processing (NLP) workloads does the solution use? Each correct\nanswer presents part of the solution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. text-to-speech",
                        "B. translation",
                        "C. language modeling",
                        "D. key phrase extraction",
                        "E. speech-to-text"
                    ],
                    "answer": [
                        "D",
                        "E"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "156",
                    "question": "DRAG DROP\nMatch the Azure Cognitive Services to the appropriate Al workloads.\nTo answer, drag the appropriate service from the column on the left to its workload on the right. Each\nservice may be used once, more than once, or not at all.\nNOTE: Each correct match is worth one point.\n<img src='images/page_116_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_117_img_1.jpg'>"
                },
                {
                    "question_number": "157",
                    "question": "An app that analyzes social media posts to identify their tone is an example of which type of natural\nlanguage processing (NLP) workload?",
                    "options": [
                        "A. sentiment analysis",
                        "B. key phrase extraction",
                        "C. entity recognition",
                        "D. speech recognition"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "158",
                    "question": "You have an Al-based loan approval system.\nDuring testing, you discover that the system has a gender bias.\nWhich responsible Al principle does this violate?",
                    "options": [
                        "A. accountability",
                        "B. transparency",
                        "C. fairness",
                        "D. reliability and safety"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "159",
                    "question": "You have a custom question answering solution.\nYou create a bot that uses the knowledge base to respond to customer requests. You need to identify\nwhat the bot can perform without adding additional skills. What should you identify?",
                    "options": [
                        "A. Register customer complaints.",
                        "B. Answer questions from multiple users simultaneously.",
                        "C. Register customer purchases.",
                        "D. Provide customers with return materials authorization (RMA) numbers."
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "160",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No. NOTE:\nEach correct selection is worth one point.\n<img src='images/page_118_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_118_img_2.jpg'>"
                },
                {
                    "question_number": "161",
                    "question": "Which machine learning technique can be used for anomaly detection?",
                    "options": [
                        "A. A machine learning technique that understands written and spoken language.",
                        "B. A machine learning technique that classifies objects based on user supplied images.",
                        "C. A machine learning technique that analyzes data over time and identifies unusual changes.",
                        "D. A machine learning technique that classifies images based on their contents."
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "162",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_118_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_119_img_1.jpg'>"
                },
                {
                    "question_number": "163",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_119_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_119_img_3.jpg'>"
                },
                {
                    "question_number": "164",
                    "question": "HOTSPOT\nSelect the .\n<img src='images/page_119_img_4.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_119_img_5.jpg'>"
                },
                {
                    "question_number": "165",
                    "question": "Your company manufactures widgets.\nYou have 1.000 digital photos of the widgets.\nYou need to identify the location of the widgets within the photos.\nWhat should you use?",
                    "options": [
                        "A. Computer Vision Spatial Analysis",
                        "B. Custom Vision object detection",
                        "C. Custom Vision classification",
                        "D. Computer Vision Image Analysis"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "166",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence\n<img src='images/page_120_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_120_img_2.jpg'>"
                },
                {
                    "question_number": "167",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence\n<img src='images/page_120_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_120_img_4.jpg'>"
                },
                {
                    "question_number": "168",
                    "question": "DRAG DROP\nYou plan to deploy an Azure Machine Learning model by using the Machine Learning designer\nWhich four actions should you perform in sequence? To answer, move the appropriate actions from\nthe list of actions to the answer area and arrange them in the correct order.\n<img src='images/page_121_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_121_img_2.jpg'>"
                },
                {
                    "question_number": "169",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_121_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_121_img_4.jpg'>"
                },
                {
                    "question_number": "170",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_122_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_122_img_2.jpg'>"
                },
                {
                    "question_number": "171",
                    "question": "For which two workloads can you use computer vision? Each correct answer presents a complete\nsolution. NOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. creating photorealistic images by using three-dimensional models",
                        "B. assigning the color pixels in an image to object names",
                        "C. describing the contents of an image",
                        "D. detecting inconsistencies and anomalies in a stream of data",
                        "E. creating visual representations of numerical data"
                    ],
                    "answer": [
                        "B",
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "172",
                    "question": "You have a website that includes customer reviews.\nYou need to store the reviews in English and present the reviews to users in their respective language\nby recognizing each user\u2019s geographical location.\nWhich type of natural language processing workload should you use?",
                    "options": [
                        "A. translation",
                        "B. language modeling",
                        "C. key phrase extraction",
                        "D. speech recognition"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "173",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_123_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_123_img_2.jpg'>"
                },
                {
                    "question_number": "174",
                    "question": "You have an Internet of Things (loT) device that monitors engine temperature.\nThe device generates an alert if the engine temperature deviates from expected norms.\nWhich type of Al workload does the device represent?",
                    "options": [
                        "A. natural language processing (NLP)",
                        "B. computer vision",
                        "C. anomaly detection",
                        "D. knowledge mining"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "175",
                    "question": "You need to create a clustering model and evaluate the model by using Azure Machine Learning\ndesigner. What should you do?",
                    "options": [
                        "A. Split the original dataset into a dataset for features and a dataset for labels. Use the features\ndataset for evaluation.",
                        "B. Split the original dataset into a dataset for training and a dataset for testing. Use the training\ndataset for evaluation.",
                        "C. Split the original dataset into a dataset for training and a dataset for testing. Use the testing\ndataset for evaluation.",
                        "D. Use the original dataset for training and evaluation."
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "176",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is True. Otherwise, select No. NOTE:\nEach correct selection is worth one point.\n<img src='images/page_124_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_124_img_2.jpg'>"
                },
                {
                    "question_number": "177",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No. NOTE:\nEach correct selection is worth one point.\n<img src='images/page_124_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_124_img_4.jpg'>"
                },
                {
                    "question_number": "178",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_125_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_125_img_2.jpg'>"
                },
                {
                    "question_number": "179",
                    "question": "Which statement is an example of a Microsoft responsible AJ principle?",
                    "options": [
                        "A. Al systems must use only publicly available data.",
                        "B. Al systems must protect the interests of the company",
                        "C. Al systems must be understandable.",
                        "D. Al systems must keep personal details public"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "180",
                    "question": "Which type of natural language processing (NLP) entity is used to identify a phone number?",
                    "options": [
                        "A. regular expression",
                        "B. machine-learned",
                        "C. list",
                        "D. Pattern-any"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "181",
                    "question": "You need to implement a pre-built solution that will identify well-known brands in digital\nphotographs. Which Azure Al sen/tee should you use?\nFaceustom Visionomputer Vision\nForm Recognizer",
                    "options": [
                        "A. Face\nB.\nCustom Vision\nC.\nComputer Vision\nD.\nForm Recognizer"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "182",
                    "question": "HOTSPOT\nFor each of the following statements. select Yes if the statement is true. Otherwise, select No. NOTE;\nEach correct selection is worth one point\n<img src='images/page_126_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_126_img_2.jpg'>"
                },
                {
                    "question_number": "183",
                    "question": "You need to identify street names based on street signs in photographs.\nWhich type of computer vision should you use?",
                    "options": [
                        "A. object detection",
                        "B. optical character recognition (OCR)",
                        "C. image classification",
                        "D. facial recognition"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "184",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_127_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_127_img_2.jpg'>"
                },
                {
                    "question_number": "185",
                    "question": "You need to reduce the load on telephone operators by implementing a Chabot to answer simple\nquestions with predefined answers.\nWhich two Al services should you use to achieve the goal? Each correct answer presents part of the\nsolution.\nNOTE: Each correct selection is worth one point.",
                    "options": [
                        "A. Azure 8ol Service",
                        "B. Azure Machine Learning",
                        "C. Translator",
                        "D. Language Service"
                    ],
                    "answer": [
                        "A",
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "186",
                    "question": "DRAG DROP\nMatch the machine learning models to the appropriate deceptions.\nTo answer, drag the appropriate model from the column on the left to its description on the right\nEach model may be used once, more than once, or not at all.\nNOTE: Each correct match is worth one point.\n<img src='images/page_128_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_128_img_2.jpg'>"
                },
                {
                    "question_number": "187",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_128_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_128_img_4.jpg'>"
                },
                {
                    "question_number": "188",
                    "question": "During the process of Machine Learning, when should you review evaluation metrics?",
                    "options": [
                        "A. After you clean the data.",
                        "B. Before you train a model.",
                        "C. Before you choose the type of model.",
                        "D. After you test a model on the validation data."
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "189",
                    "question": "Which Azure Cognitive Services service can be used to identify documents that contain sensitive\ninformation?",
                    "options": [
                        "A. Custom Vision",
                        "B. Conversational Language Understanding",
                        "C. Form Recognizer"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "190",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_129_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_129_img_2.jpg'>"
                },
                {
                    "question_number": "191",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_129_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_130_img_1.jpg'>"
                },
                {
                    "question_number": "192",
                    "question": "You have a bot that identifies the brand names of products in images of supermarket shelves.\nWhich service does the bot use?",
                    "options": [
                        "A. Al enrichment for Azure Search capabilities",
                        "B. Computer Vision Image Analysis capabilities",
                        "C. Custom Vision Image Classification capabilities",
                        "D. Language understanding capabilities"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "193",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_130_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_130_img_3.jpg'>"
                },
                {
                    "question_number": "194",
                    "question": "HOTSPOT\nYou have an app that identifies birds in images. The app performs the following tasks:\n* Identifies the location of the birds in the image\n* Identifies the species of the birds in the image\nWhich type of computer vision does each task use? To answer, select the appropriate options in the\nanswer area.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_131_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_131_img_2.jpg'>"
                },
                {
                    "question_number": "195",
                    "question": "HOTSPOT\nTo complete the sentence, select the appropriate option in the answer area.\n<img src='images/page_131_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_131_img_4.jpg'>"
                },
                {
                    "question_number": "196",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_131_img_5.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_132_img_1.jpg'>"
                },
                {
                    "question_number": "197",
                    "question": "You have a natural language processing (NIP) model that was created by using data obtained without\npermission.\nWhich Microsoft principle for responsible Al does this breach?",
                    "options": [
                        "A. privacy and security",
                        "B. inclusiveness",
                        "C. transparency",
                        "D. reliability and safety"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "198",
                    "question": "Which two languages can you use to write custom code for Azure Machine Learning designer? Each\ncorrect answer presents a complete solution.\nNOTE; Each correct selection is worth one point.",
                    "options": [
                        "A. C#",
                        "B. Scala",
                        "C. Python",
                        "D. R"
                    ],
                    "answer": [
                        "C",
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "199",
                    "question": "You need to predict the animal population of an area.\nWhich Azure Machine Learning type should you use?",
                    "options": [
                        "A. clustering",
                        "B. classification",
                        "C. regression"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "200",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_133_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_133_img_2.jpg'>"
                },
                {
                    "question_number": "201",
                    "question": "Which two scenarios are examples of a natural language processing workload? Each correct answer\npresents a complete solution.\nNOTE; Each correct selection is worth one point.",
                    "options": [
                        "A. assembly line machinery that autonomously inserts headlamps into cars",
                        "B. a smart device in the home that responds to questions such as, \"What will the weather be like\ntoday?",
                        "C. monitoring the temperature of machinery to turn on a fan when the temperature reaches a\nspecific threshold",
                        "D. a website that uses a knowledge base to interactively respond to users' questions"
                    ],
                    "answer": [
                        "B",
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "202",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_134_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_134_img_2.jpg'>"
                },
                {
                    "question_number": "203",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_134_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_134_img_4.jpg'>"
                },
                {
                    "question_number": "204",
                    "question": "Which Computer Vision feature can you use to generate automatic captions for digital photographs?",
                    "options": [
                        "A. Recognize text.",
                        "B. Describe the images.",
                        "C. Identify the areas of interest.",
                        "D. Detect objects."
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "205",
                    "question": "You plan to build a conversational Al solution that can be surfaced in Microsoft Teams. Microsoft\nCortana, and Amazon Alex\na. Which service should you use?",
                    "options": [
                        "A. Azure Bot Service",
                        "B. Azure Cognitive Search",
                        "C. Language service",
                        "D. Speech"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "206",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_135_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_135_img_2.jpg'>"
                },
                {
                    "question_number": "207",
                    "question": "You have an Azure Machine Learning model that uses clinical data to predict whether a patient has a\ndisease.\nYou clean and transform the clinical data.\nYou need to ensure that the accuracy of the model can be proven.\nWhat should you do next?",
                    "options": [
                        "A. Train the model by using the clinical data.",
                        "B. Split the clinical data into Two datasets.",
                        "C. Train the model by using automated machine learning (automated ML).",
                        "D. Validate the model by using the clinical data."
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "208",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE; Each correct selection is worth one point.\n<img src='images/page_136_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_136_img_2.jpg'>"
                },
                {
                    "question_number": "209",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE; Each correct selection is worth one point.\n<img src='images/page_136_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_137_img_1.jpg'>"
                },
                {
                    "question_number": "210",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE; Each correct selection is worth one point.\n<img src='images/page_137_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_137_img_3.jpg'>"
                },
                {
                    "question_number": "211",
                    "question": "DRAG DROP\nMatch the tasks to the appropriate machine learning models.\nTo answer, drag the appropriate model from the column on the left to its scenario on the right. Each\nmodel may be used once, more than once, or not at all.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_138_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_138_img_2.jpg'>"
                },
                {
                    "question_number": "212",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_138_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_138_img_4.jpg'>"
                },
                {
                    "question_number": "213",
                    "question": "A smart device that responds to the question. \"What is the stock price of Contoso, Ltd.?\" is an\nexample of which Al workload?",
                    "options": [
                        "A. computer vision",
                        "B. anomaly detection",
                        "C. knowledge mining",
                        "D. natural language processing"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "214",
                    "question": "What is an advantage of using a custom model in Form Recognizer?",
                    "options": [
                        "A. Only a custom model can be deployed on-premises.",
                        "B. A custom model can be trained to recognize a variety of form types.",
                        "C. A custom model is less expensive than a prebuilt model.",
                        "D. A custom model always provides higher accuracy."
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "215",
                    "question": "Which Azure Al Language feature can be used to retrieve data, such as dates and people's names,\nfrom social media posts?",
                    "options": [
                        "A. language detection",
                        "B. speech recognition",
                        "C. key phrase extraction",
                        "D. entity recognition"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "216",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_139_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_139_img_2.jpg'>"
                },
                {
                    "question_number": "217",
                    "question": "Which parameter should you configure to produce more verbose responses from a chat solution that\nuses the Azure OpenAI GPT-3.5 model?",
                    "options": [
                        "A. Presence penalty",
                        "B. Temperature",
                        "C. Stop sequence",
                        "D. Max response"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "218",
                    "question": "Which three actions improve the quality of responses returned by a generative Al solution that uses\nGPT-3.5? Each correct answer presents a complete solution.\nNOTE: Each correct answer is worth one point.",
                    "options": [
                        "A. Add grounding data to prompts.",
                        "B. Provide additional examples to prompts.",
                        "C. Modify tokenization.",
                        "D. Add training data to prompts.",
                        "E. Modify system messages."
                    ],
                    "answer": [
                        "B",
                        "D",
                        "E"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "219",
                    "question": "DRAG DROP\nMatch the Azure OpenAI large language model (LLM) process to the appropriate task.\nTo answer, drag the appropriate process from the column on the left to its task on the right. Each\nprocess may be used once, more than once, or not at all.\nNOTE: Each correct match is worth one point.\n<img src='images/page_140_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_141_img_1.jpg'>"
                },
                {
                    "question_number": "220",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_141_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_141_img_3.jpg'>"
                },
                {
                    "question_number": "221",
                    "question": "DRAG DROP\nMatch the computer vision service to the appropriate Al workload.\nTo answer, drag the appropriate service from the column on the left to its workload on the right. Each\nservice may be used once, more than once, or not at all.\nNOTE: Each correct match is worth one point.\n<img src='images/page_141_img_4.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_142_img_1.jpg'>"
                },
                {
                    "question_number": "222",
                    "question": "What are three stages in a transformer model? Each correct answer presents a complete solution.\nNOTE: Each correct answer is worth one point.",
                    "options": [
                        "A. object detection",
                        "B. embedding calculation",
                        "C. tokenization",
                        "D. next token prediction",
                        "E. anonymization"
                    ],
                    "answer": [
                        "B",
                        "C",
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "223",
                    "question": "What can be used to complete a paragraph based on a sentence provided by a user?",
                    "options": [
                        "A. Azure Al Language",
                        "B. Azure OpenAI",
                        "C. Azure Machine Learning",
                        "D. Azure Al Vision"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "224",
                    "question": "You need to generate cartoons for use in a brochure. Each cartoon will be based on a text\ndescription.\nWhich Azure OpenAI model should you use?",
                    "options": [
                        "A. Codex",
                        "B. DALL-E",
                        "C. GPT-3.5",
                        "D. GPT-4"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "225",
                    "question": "You need to create a model that labels a collection of your personal digital photographs.\nWhich Azure Al service should you use?",
                    "options": [
                        "A. Azure Al Language",
                        "B. Azure Al Computer Vision",
                        "C. Azure Al Document Intelligence",
                        "D. Azure Al Custom Vision"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "226",
                    "question": "You need to build an app that will identify celebrities in images.\nWhich service should you use?",
                    "options": [
                        "A. Azure OpenAI Service",
                        "B. Azure Machine Learning",
                        "C. conversational language understanding (CLU)",
                        "D. Azure Al Vision"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "227",
                    "question": "You have an app that identifies the coordinates of a product in an image of a supermarket shelf.\nWhich service does the app use?",
                    "options": [
                        "A. Azure Al Custom Vision object detection",
                        "B. Azure Al Computer Vision Read",
                        "C. Azure Al Computer Vision optical character recognition (OCR)",
                        "D. Azure Al Custom Vision classification"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "228",
                    "question": "You need to convert receipts into transactions in a spreadsheet. The spreadsheet must include the\ndate of the transaction, the merchant the total spent and any taxes paid.\nWhich Azure Al service should you use?",
                    "options": [
                        "A. Face",
                        "B. Azure Al Language",
                        "C. Azure Al Document Intelligence",
                        "D. Azure Al Custom Vision"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "229",
                    "question": "DRAG DROP\nYou plan to use Azure Cognitive Services to develop a voice controlled personal assistant app.\nMatch the Azure Cognitive Services to the appropriate tasks.\nTo answer, drag the appropriate service from the column on the left to its description on the right\nEach service may be used once, more than once, or not at all.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_144_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_145_img_1.jpg'>"
                },
                {
                    "question_number": "230",
                    "question": "You have a chatbot that answers technical questions by using the Azure OpenAI GPT-3.5 large\nlanguage model (LLM). Which two statements accurately describe the chatbot? Each correct answer\npresents a complete solution.\nNOTE: Each correct answer is worth one point.",
                    "options": [
                        "A. Grounding data can be used to constrain the output of the chatbot.",
                        "B. The chatbot will always provide accurate data.",
                        "C. The chatbot might respond with inaccurate data.",
                        "D. The chatbot is suitable for performing medical diagnosis."
                    ],
                    "answer": [
                        "A",
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "231",
                    "question": "You have a dataset that contains experimental data for fuel samples.\nYou need to predict the amount of energy that can be obtained from a sample based on its density.\nWhich type of Al workload should you use?",
                    "options": [
                        "A. Classification",
                        "B. Clustering",
                        "C. Knowledge mining",
                        "D. Regression"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "232",
                    "question": "Which two tools can you use to call the Azure OpenAI service? Each correct answer presents a\ncomplete solution.\nNOTE: Each correct answer is worth one point.",
                    "options": [
                        "A. Azure Command-Line Interface (CLI)",
                        "B. Azure REST API",
                        "C. Azure SDK for Python",
                        "D. Azure SDK for JavaScript"
                    ],
                    "answer": [
                        "A",
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "233",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n<img src='images/page_146_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_146_img_2.jpg'>"
                },
                {
                    "question_number": "234",
                    "question": "You are building a tool that will process images from retail stores and identity the products of\ncompetitors.\nThe solution must be trained on images provided by your company.\nWhich Azure Al service should you use?",
                    "options": [
                        "A. Azure Al Custom Vision",
                        "B. Azure Al Computer Vision",
                        "C. Face",
                        "D. Azure Al Document Intelligence"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "235",
                    "question": "DRAG DROP\nMatch the types of computer vision workloads to the appropriate scenarios.\nTo answer, drag the appropriate workload type from the column on the left to its scenario on the\nright. Each workload type may be used once more than once, or not at all.\nNOTE: Each correct match is worth one point.\n<img src='images/page_147_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_147_img_2.jpg'>"
                },
                {
                    "question_number": "236",
                    "question": "You need to generate images based on user prompts. Which Azure OpenAI model should you use?",
                    "options": [
                        "A. GPT-4",
                        "B. DALL-E",
                        "C. GPT-3",
                        "D. Whisper"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "237",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No. NOTE:\nEach correct selection is worth one point.\n<img src='images/page_148_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_148_img_2.jpg'>"
                },
                {
                    "question_number": "238",
                    "question": "Extracting relationships between data from large volumes of unstructured data is an example of\nwhich type of Al workload?",
                    "options": [
                        "A. computer vision",
                        "B. knowledge mining",
                        "C. natural language processing (NLP)",
                        "D. anomaly detection"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "239",
                    "question": "Which Azure service can use the prebuilt receipt model in Azure Al Document Intelligence?",
                    "options": [
                        "A. Azure Al Computer Vision",
                        "B. Azure Machine Learning",
                        "C. Azure Al Services",
                        "D. Azure Al Custom Vision"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "240",
                    "question": "You plan to use Azure Machine Learning Studio and automated machine learning (automated ML) to\nbuild and train a model What should you create first?",
                    "options": [
                        "A. a Jupyter notebook",
                        "B. a Machine Learning workspace",
                        "C. a registered dataset",
                        "D. a Machine Learning designer pipeline"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "241",
                    "question": "DRAG DROP\nYou are designing a system that will generate insurance quotes automatically.\nMatch the Microsoft responsible Al principles to the appropriate requirements.\nTo answer, drag the appropriate principle from the column on the left to its requirement on the right\nEach principle may be used once, more than once, or not at all.\nNOTE: Each correct match is worth one point.\n<img src='images/page_149_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_149_img_2.jpg'>"
                },
                {
                    "question_number": "242",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_150_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_150_img_2.jpg'>"
                },
                {
                    "question_number": "243",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_150_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_150_img_4.jpg'>"
                },
                {
                    "question_number": "244",
                    "question": "Which two resources can you use to analyze code and generate explanations of code function and\ncode comments? Each correct answer presents a complete solution.\nNOTE: Each correct answer is worth one point.",
                    "options": [
                        "A. the Azure OpenAI DALL-E model",
                        "B. the Azure OpenAI Whisper model",
                        "C. the Azure OpenAI GPT-4 model",
                        "D. the GitHub Copilot service"
                    ],
                    "answer": [
                        "A",
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "245",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_151_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_151_img_2.jpg'>"
                },
                {
                    "question_number": "246",
                    "question": "You need to count the number of animals in a photograph. Which type of computer vision should you\nuse?",
                    "options": [
                        "A. facial detection",
                        "B. image classification",
                        "C. optical character recognition (OCR)",
                        "D. object detection"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "247",
                    "question": "You need to analyze images of vehicles on a highway and measure the distance between the\nvehicles. Which type of computer vision model should you use?",
                    "options": [
                        "A. object detection",
                        "B. image classification",
                        "C. facial recognition",
                        "D. optical character recognition (OCR)"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "248",
                    "question": "You have 100 instructional videos that do NOT contain any audio. Each instructional video has a\nscript. You need to generate a narration audio file for each video based on the script. Which type of\nworkload should you use?",
                    "options": [
                        "A. speech recognition",
                        "B. language modeling",
                        "C. speech synthesis",
                        "D. translation"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "249",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_153_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_153_img_2.jpg'>"
                },
                {
                    "question_number": "250",
                    "question": "DRAG DROP\nMatch the Azure Al service to the appropriate actions.\nTo answer, drag the appropriate service from the column on the left to its action on the right Each\nservice may be used once, more than once, or not at all.\nNOTE: Each correct match is worth one point.\n<img src='images/page_154_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_154_img_2.jpg'>"
                },
                {
                    "question_number": "251",
                    "question": "HOTSPOT\nFor each of The following statements, select Yes If the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point\n<img src='images/page_154_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_155_img_1.jpg'>"
                },
                {
                    "question_number": "252",
                    "question": "You need to provide customers with the ability to query the status of orders by using phones, social\nmedia, or digital assistants.\nWhat should you use?",
                    "options": [
                        "A. Azure Al Bot Service",
                        "B. the Azure Al Translator service",
                        "C. an Azure Al Document Intelligence model",
                        "D. an Azure Machine Learning model"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "253",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_155_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_156_img_1.jpg'>"
                },
                {
                    "question_number": "254",
                    "question": "What is an example of unsupervised machine learning?",
                    "options": [
                        "A. classification",
                        "B. clustering",
                        "C. regression"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "255",
                    "question": "Which action can be performed by using the Azure Al Vision service?",
                    "options": [
                        "A. identifying breeds of animals in live video streams",
                        "B. extracting key phrases from documents",
                        "C. extracting data from handwritten letters",
                        "D. creating thumbnails for training videos"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "256",
                    "question": "What is an example of a Microsoft responsible Al principle?",
                    "options": [
                        "A. Al systems should protect the interests of developers.",
                        "B. Al systems should be in the public domain.",
                        "C. Al systems should be secure and respect privacy.",
                        "D. Al systems should make personal details accessible."
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "257",
                    "question": "You need to identify groups of rows with similar numeric values in a dataset. Which type of machine\nlearning should you use?",
                    "options": [
                        "A. clustering",
                        "B. regression",
                        "C. classification"
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "258",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point\n<img src='images/page_158_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_158_img_2.jpg'>"
                },
                {
                    "question_number": "259",
                    "question": "Which OpenAI model does GitHub Copilot use to make suggestions for client-side JavaScript?",
                    "options": [
                        "A. GPT-4",
                        "B. Codex",
                        "C. DALL-E",
                        "D. GPT-3"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "260",
                    "question": "Which format should you use to send requests to a REST API endpoint for Azure OpenAI?",
                    "options": [
                        "A. CSV",
                        "B. ISON",
                        "C. XML",
                        "D. YAML"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "261",
                    "question": "DRAG DROP\nMatch the Al solution to the appropriate task.\nTo answer, drag the appropriate solution from the column on the left to its task on the right. Each\nsolution may be used once, more than once, or not at all.\nNOTE: Each correct match is worth one point.\n<img src='images/page_159_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_160_img_1.jpg'>"
                },
                {
                    "question_number": "262",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE Each correct selection is worth one point\n<img src='images/page_160_img_2.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_160_img_3.jpg'>"
                },
                {
                    "question_number": "263",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_161_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_161_img_2.jpg'>"
                },
                {
                    "question_number": "264",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.",
                    "options": [],
                    "answer": [],
                    "explanation": ""
                },
                {
                    "question_number": "265",
                    "question": "You are building an Al-based loan approval app.\nYou need to ensure that the app documents why a loan is approved or rejected and makes the report\navailable to the applicant.\nThis is an example of which Microsoft responsible Al principle?",
                    "options": [
                        "A. fairness",
                        "B. inclusiveness",
                        "C. transparency",
                        "D. accountability"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "266",
                    "question": "Which Azure Al Document Intelligence prebuilt model should you use to extract parties and\njurisdictions from a legal document?",
                    "options": [
                        "A. contract",
                        "B. layout",
                        "C. general document",
                        "D. read"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "267",
                    "question": "What is an example of a regression model in machine learning?",
                    "options": [
                        "A. dividing the student data in a dataset based on the age of the students and their educational\nachievements",
                        "B. identifying subtypes of spam email by examining a large collection of emails that were flagged by\nusers",
                        "C. predicting the sale price of a house based on historical data, the size of the house, and the number\nof bedrooms in the house",
                        "D. identifying population counts of endangered animals by analyzing images"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "268",
                    "question": "What should you do to reduce the number of false positives produced by a machine learning\nclassification model?",
                    "options": [
                        "A. Include test data in the training data.",
                        "B. Increase the number of training iterations.",
                        "C. Modify the threshold value in favor of false positives.",
                        "D. Modify the threshold value in favor of false negatives."
                    ],
                    "answer": [
                        "A"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "269",
                    "question": "You need to predict the population size of a specific species of animal in an area.\nWhich Azure Machine Learning type should you use?",
                    "options": [
                        "A. clustering",
                        "B. regression",
                        "C. classification"
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "270",
                    "question": "Which parameter should you configure to produce a more diverse range of tokens in the responses\nfrom a chat solution that uses the Azure OpenAI GPT-3.5 model?",
                    "options": [
                        "A. Max response",
                        "B. Past messages included",
                        "C. Presence penalty",
                        "D. Stop sequence"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "271",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_163_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_163_img_2.jpg'>"
                },
                {
                    "question_number": "272",
                    "question": "Providing contextual information to improve the responses quality of a generative Al solution is an\nexample of which prompt engineering technique?",
                    "options": [
                        "A. providing examples",
                        "B. fine-tuning",
                        "C. grounding data",
                        "D. system messages"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "273",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_164_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_164_img_2.jpg'>"
                },
                {
                    "question_number": "274",
                    "question": "DRAG DROP\nMatch the Al workload to the appropriate task.\nTo answer, drag the appropriate Ai workload from the column on the left to its task on the right. Each\nworkload may be used once, more than once, or not at all.\nNOTE: Each correct match is worth one point.\n<img src='images/page_164_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_165_img_1.jpg'>"
                },
                {
                    "question_number": "275",
                    "question": "Which term is used to describe uploading your own data to customize an Azure OpenAI model?",
                    "options": [
                        "A. completion",
                        "B. grounding",
                        "C. fine -tuning",
                        "D. prompt engineering"
                    ],
                    "answer": [
                        "C"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "276",
                    "question": "What should you implement to identify hateful responses returned by a generative Al solution?",
                    "options": [
                        "A. prompt engineering",
                        "B. abuse monitoring",
                        "C. content filtering",
                        "D. fine-tuning"
                    ],
                    "answer": [
                        "D"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "277",
                    "question": "What should you do to ensure that an Azure OpenAI model generates accurate responses that\ninclude recent events?",
                    "options": [
                        "A. Modify the system message.",
                        "B. Add grounding data.",
                        "C. Add few-shot learning.",
                        "D. Add training data."
                    ],
                    "answer": [
                        "B"
                    ],
                    "explanation": ""
                },
                {
                    "question_number": "278",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_166_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_166_img_2.jpg'>"
                },
                {
                    "question_number": "279",
                    "question": "HOTSPOT\nSelect the answer that correctly completes the sentence.\n<img src='images/page_166_img_3.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_166_img_4.jpg'>"
                },
                {
                    "question_number": "280",
                    "question": "HOTSPOT\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE; Each correct selection is worth one point.\n<img src='images/page_167_img_1.jpg'>",
                    "options": [],
                    "answer": [],
                    "explanation": "<img src='images/page_167_img_2.jpg'>"
                },
                {
                    "question_number": "281",
                    "question": "You need to provide content for a business chatbot that will help answer simple user queries.\nWhat are three ways to create question and answer text by using Azure Al Language Service's\nquestion answering? Each correct answer presents a complete solution.\nNOTE: Each correct and ask questions by selection is worth one point.",
                    "options": [
                        "A. Connect the bot to the Cortana channel using Cortana.",
                        "B. Import chit-chat content from a predefined data source.",
                        "C. Manually enter the questions and answers.",
                        "D. Use Azure Machine Learning Automated ML to train a model based on a file that contains question\nand answer pairs.",
                        "E. Generate the questions and answers from an existing webpage."
                    ],
                    "answer": [
                        "B",
                        "C",
                        "E"
                    ],
                    "explanation": ""
                }
            ]
        }
    }
}